{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "749121e1-36ed-4acd-baea-9c7477e99e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: OMP_NUM_THREADS set to 14, not 1. The computation speed will not be optimized if you use data parallel. It will fail if this PaddlePaddle binary is compiled with OpenBlas since OpenBlas does not support multi-threads.\n",
      "PLEASE USE OMP_NUM_THREADS WISELY.\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.optimizer as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from numpy.core.defchararray import decode, mod\n",
    "import paddle\n",
    "import numpy as np\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph import to_variable\n",
    "from paddle.fluid.dygraph import Layer\n",
    "from paddle.fluid.dygraph import Conv2D\n",
    "from paddle.fluid.dygraph import BatchNorm\n",
    "from paddle.fluid.dygraph import Pool2D\n",
    "from paddle.fluid.dygraph import Conv2DTranspose\n",
    "from visualdl import LogWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef6f8bd-6d9d-4777-a36d-5767da5b80cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.nn as nn\n",
    "\n",
    "class FCN(nn.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(FCN, self).__init__()\n",
    "        \n",
    "        # 基础特征提取网络，这里简化地使用VGG16的前几层作为示例\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2D(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2D(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # 分割头\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2D(128, num_classes, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return nn.functional.interpolate(x, scale_factor=4, mode='bilinear', align_corners=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014240f7-62fc-44d5-87b4-d94cb33fdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据加载\n",
    "class EyeDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform_size=(512, 512)):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform_size = transform_size\n",
    "        self.image_list = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_list[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, os.path.splitext(self.image_list[idx])[0] + '.bmp')\n",
    "        \n",
    "        # 使用resize方法调整图像和掩码的尺寸\n",
    "        image = Image.open(image_path).convert('RGB').resize(self.transform_size)\n",
    "        mask = Image.open(mask_path).convert('L').resize(self.transform_size)\n",
    "        \n",
    "        image = paddle.to_tensor(np.array(image).astype('float32').transpose((2, 0, 1)) / 255.0)\n",
    "        mask = paddle.to_tensor(np.array(mask).astype('float32')[np.newaxis, :, :] / 255.0)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "data_dir = \"data/Train\"\n",
    "fundus_image_dir = os.path.join(data_dir, \"fundus_image\")\n",
    "completed_masks_dir = os.path.join(data_dir, \"Lesion_Masks\", \"Completed_Masks\", \"Atrophy\")  # 使用Atrophy作为示例\n",
    "\n",
    "train_dataset = EyeDataset(fundus_image_dir, completed_masks_dir, transform_size=(512,512))\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446b8f9-3120-4ba9-93ca-e21434ea80d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 14:46:16.231634   812 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.0, Runtime API Version: 11.2\n",
      "W0813 14:46:16.235545   812 device_context.cc:465] device: 0, cuDNN Version: 8.1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Batch 1/100, Loss: 0.6972641944885254\n",
      "Epoch 1/50, Batch 2/100, Loss: 0.640304446220398\n",
      "Epoch 1/50, Batch 3/100, Loss: 0.5162877440452576\n",
      "Epoch 1/50, Batch 4/100, Loss: 0.3437727987766266\n",
      "Epoch 1/50, Batch 5/100, Loss: 0.45182985067367554\n",
      "Epoch 1/50, Batch 6/100, Loss: 0.48747414350509644\n",
      "Epoch 1/50, Batch 7/100, Loss: 0.5922821760177612\n",
      "Epoch 1/50, Batch 8/100, Loss: 0.4565608501434326\n",
      "Epoch 1/50, Batch 9/100, Loss: 0.44956302642822266\n",
      "Epoch 1/50, Batch 10/100, Loss: 0.38592323660850525\n",
      "Epoch 1/50, Batch 11/100, Loss: 0.46263521909713745\n",
      "Epoch 1/50, Batch 12/100, Loss: 0.3065298795700073\n",
      "Epoch 1/50, Batch 13/100, Loss: 0.24199403822422028\n",
      "Epoch 1/50, Batch 14/100, Loss: 0.3981825113296509\n",
      "Epoch 1/50, Batch 15/100, Loss: 0.3033033311367035\n",
      "Epoch 1/50, Batch 16/100, Loss: 0.23130947351455688\n",
      "Epoch 1/50, Batch 17/100, Loss: 0.24126487970352173\n",
      "Epoch 1/50, Batch 18/100, Loss: 0.241043359041214\n",
      "Epoch 1/50, Batch 19/100, Loss: 0.3429095447063446\n",
      "Epoch 1/50, Batch 20/100, Loss: 0.273842453956604\n",
      "Epoch 1/50, Batch 21/100, Loss: 0.49157288670539856\n",
      "Epoch 1/50, Batch 22/100, Loss: 0.41475412249565125\n",
      "Epoch 1/50, Batch 23/100, Loss: 0.32367828488349915\n",
      "Epoch 1/50, Batch 24/100, Loss: 0.33231663703918457\n",
      "Epoch 1/50, Batch 25/100, Loss: 0.3822888731956482\n",
      "Epoch 1/50, Batch 26/100, Loss: 0.34583693742752075\n",
      "Epoch 1/50, Batch 27/100, Loss: 0.2409035861492157\n",
      "Epoch 1/50, Batch 28/100, Loss: 0.26881295442581177\n",
      "Epoch 1/50, Batch 29/100, Loss: 0.13973118364810944\n",
      "Epoch 1/50, Batch 30/100, Loss: 0.38523241877555847\n",
      "Epoch 1/50, Batch 31/100, Loss: 0.5312930941581726\n",
      "Epoch 1/50, Batch 32/100, Loss: 0.3305189609527588\n",
      "Epoch 1/50, Batch 33/100, Loss: 0.33157145977020264\n",
      "Epoch 1/50, Batch 34/100, Loss: 0.24619868397712708\n",
      "Epoch 1/50, Batch 35/100, Loss: 0.28201359510421753\n",
      "Epoch 1/50, Batch 36/100, Loss: 0.34556928277015686\n",
      "Epoch 1/50, Batch 37/100, Loss: 0.2854263186454773\n",
      "Epoch 1/50, Batch 38/100, Loss: 0.25802499055862427\n",
      "Epoch 1/50, Batch 39/100, Loss: 0.2596617043018341\n",
      "Epoch 1/50, Batch 40/100, Loss: 0.2758738398551941\n",
      "Epoch 1/50, Batch 41/100, Loss: 0.19652824103832245\n",
      "Epoch 1/50, Batch 42/100, Loss: 0.44756636023521423\n",
      "Epoch 1/50, Batch 43/100, Loss: 0.18154479563236237\n",
      "Epoch 1/50, Batch 44/100, Loss: 0.4588773250579834\n",
      "Epoch 1/50, Batch 45/100, Loss: 0.08130807429552078\n",
      "Epoch 1/50, Batch 46/100, Loss: 0.06054603308439255\n",
      "Epoch 1/50, Batch 47/100, Loss: 0.16541343927383423\n",
      "Epoch 1/50, Batch 48/100, Loss: 0.1230265349149704\n",
      "Epoch 1/50, Batch 49/100, Loss: 0.13323891162872314\n",
      "Epoch 1/50, Batch 50/100, Loss: 0.09890306740999222\n",
      "Epoch 1/50, Batch 51/100, Loss: 0.1874365359544754\n",
      "Epoch 1/50, Batch 52/100, Loss: 0.33146753907203674\n",
      "Epoch 1/50, Batch 53/100, Loss: 0.3081812262535095\n",
      "Epoch 1/50, Batch 54/100, Loss: 0.1669885814189911\n",
      "Epoch 1/50, Batch 55/100, Loss: 0.1884865164756775\n",
      "Epoch 1/50, Batch 56/100, Loss: 0.18453578650951385\n",
      "Epoch 1/50, Batch 57/100, Loss: 0.18928262591362\n",
      "Epoch 1/50, Batch 58/100, Loss: 0.1906297653913498\n",
      "Epoch 1/50, Batch 59/100, Loss: 0.14513549208641052\n",
      "Epoch 1/50, Batch 60/100, Loss: 0.24395382404327393\n",
      "Epoch 1/50, Batch 61/100, Loss: 0.3472144305706024\n",
      "Epoch 1/50, Batch 62/100, Loss: 0.15245243906974792\n",
      "Epoch 1/50, Batch 63/100, Loss: 0.17111057043075562\n",
      "Epoch 1/50, Batch 64/100, Loss: 0.1595800817012787\n",
      "Epoch 1/50, Batch 65/100, Loss: 0.3012157678604126\n",
      "Epoch 1/50, Batch 66/100, Loss: 0.23266173899173737\n",
      "Epoch 1/50, Batch 67/100, Loss: 0.39176642894744873\n",
      "Epoch 1/50, Batch 68/100, Loss: 0.0973493829369545\n",
      "Epoch 1/50, Batch 69/100, Loss: 0.2255389243364334\n",
      "Epoch 1/50, Batch 70/100, Loss: 0.128117173910141\n",
      "Epoch 1/50, Batch 71/100, Loss: 0.15801599621772766\n",
      "Epoch 1/50, Batch 72/100, Loss: 0.12914980947971344\n",
      "Epoch 1/50, Batch 73/100, Loss: 0.1462700217962265\n",
      "Epoch 1/50, Batch 74/100, Loss: 0.2266186773777008\n",
      "Epoch 1/50, Batch 75/100, Loss: 0.24644167721271515\n",
      "Epoch 1/50, Batch 76/100, Loss: 0.32599765062332153\n",
      "Epoch 1/50, Batch 77/100, Loss: 0.21257874369621277\n",
      "Epoch 1/50, Batch 78/100, Loss: 0.2636731266975403\n",
      "Epoch 1/50, Batch 79/100, Loss: 0.3109060525894165\n",
      "Epoch 1/50, Batch 80/100, Loss: 0.23428131639957428\n",
      "Epoch 1/50, Batch 81/100, Loss: 0.20640677213668823\n",
      "Epoch 1/50, Batch 82/100, Loss: 0.1812203824520111\n",
      "Epoch 1/50, Batch 83/100, Loss: 0.2515908479690552\n",
      "Epoch 1/50, Batch 84/100, Loss: 0.20683211088180542\n",
      "Epoch 1/50, Batch 85/100, Loss: 0.10424995422363281\n",
      "Epoch 1/50, Batch 86/100, Loss: 0.212511345744133\n",
      "Epoch 1/50, Batch 87/100, Loss: 0.3659285306930542\n",
      "Epoch 1/50, Batch 88/100, Loss: 0.11617067456245422\n",
      "Epoch 1/50, Batch 89/100, Loss: 0.1874714195728302\n",
      "Epoch 1/50, Batch 90/100, Loss: 0.23719464242458344\n",
      "Epoch 1/50, Batch 91/100, Loss: 0.21526888012886047\n",
      "Epoch 1/50, Batch 92/100, Loss: 0.1415300816297531\n",
      "Epoch 1/50, Batch 93/100, Loss: 0.17031343281269073\n",
      "Epoch 1/50, Batch 94/100, Loss: 0.15382656455039978\n",
      "Epoch 1/50, Batch 95/100, Loss: 0.08300265669822693\n",
      "Epoch 1/50, Batch 96/100, Loss: 0.5353320837020874\n",
      "Epoch 1/50, Batch 97/100, Loss: 0.28257760405540466\n",
      "Epoch 1/50, Batch 98/100, Loss: 0.16114382445812225\n",
      "Epoch 1/50, Batch 99/100, Loss: 0.1889512836933136\n",
      "Epoch 1/50, Batch 100/100, Loss: 0.15803314745426178\n",
      "Epoch 1/50, Average Loss: 0.2723910389840603\n",
      "Saved model parameters to FCN_models/FCN_epoch1.pdparams\n",
      "Epoch 1 training time: 81.97 seconds\n",
      "Epoch 2/50, Batch 1/100, Loss: 0.19125515222549438\n",
      "Epoch 2/50, Batch 2/100, Loss: 0.18554262816905975\n",
      "Epoch 2/50, Batch 3/100, Loss: 0.27268096804618835\n",
      "Epoch 2/50, Batch 4/100, Loss: 0.19330525398254395\n",
      "Epoch 2/50, Batch 5/100, Loss: 0.20569190382957458\n",
      "Epoch 2/50, Batch 6/100, Loss: 0.22431103885173798\n",
      "Epoch 2/50, Batch 7/100, Loss: 0.1462240219116211\n",
      "Epoch 2/50, Batch 8/100, Loss: 0.17015178501605988\n",
      "Epoch 2/50, Batch 9/100, Loss: 0.19123584032058716\n",
      "Epoch 2/50, Batch 10/100, Loss: 0.41504138708114624\n",
      "Epoch 2/50, Batch 11/100, Loss: 0.1404484212398529\n",
      "Epoch 2/50, Batch 12/100, Loss: 0.21600067615509033\n",
      "Epoch 2/50, Batch 13/100, Loss: 0.20327602326869965\n",
      "Epoch 2/50, Batch 14/100, Loss: 0.2026078701019287\n",
      "Epoch 2/50, Batch 15/100, Loss: 0.13738848268985748\n",
      "Epoch 2/50, Batch 16/100, Loss: 0.1292213350534439\n",
      "Epoch 2/50, Batch 17/100, Loss: 0.1820942610502243\n",
      "Epoch 2/50, Batch 18/100, Loss: 0.3270503878593445\n",
      "Epoch 2/50, Batch 19/100, Loss: 0.2638610005378723\n",
      "Epoch 2/50, Batch 20/100, Loss: 0.20297183096408844\n",
      "Epoch 2/50, Batch 21/100, Loss: 0.16656167805194855\n",
      "Epoch 2/50, Batch 22/100, Loss: 0.16404274106025696\n",
      "Epoch 2/50, Batch 23/100, Loss: 0.13844609260559082\n",
      "Epoch 2/50, Batch 24/100, Loss: 0.3093559443950653\n",
      "Epoch 2/50, Batch 25/100, Loss: 0.2303357571363449\n",
      "Epoch 2/50, Batch 26/100, Loss: 0.19330327212810516\n",
      "Epoch 2/50, Batch 27/100, Loss: 0.12516917288303375\n",
      "Epoch 2/50, Batch 28/100, Loss: 0.13331617414951324\n",
      "Epoch 2/50, Batch 29/100, Loss: 0.1665988713502884\n",
      "Epoch 2/50, Batch 30/100, Loss: 0.28285300731658936\n",
      "Epoch 2/50, Batch 31/100, Loss: 0.22028848528862\n",
      "Epoch 2/50, Batch 32/100, Loss: 0.14890843629837036\n",
      "Epoch 2/50, Batch 33/100, Loss: 0.23280584812164307\n"
     ]
    }
   ],
   "source": [
    "import time  # 导入time模块\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "# 创建一个LogWriter对象\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "log_dir = f\"FCN_vdl_logs/{current_time}_epochs_{epochs}\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "writer = LogWriter(log_dir)\n",
    "\n",
    "# 3. 模型训练\n",
    "model = FCN(num_classes=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(parameters=model.parameters(), learning_rate=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()  # 记录epoch开始时间\n",
    "    \n",
    "    for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        \n",
    "        total_loss += loss.numpy()[0]\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.numpy()[0]}\")\n",
    "    \n",
    "    # 记录平均loss到VisualDL\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    writer.add_scalar(tag=\"train/avg_loss\", step=epoch, value=avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss}\")\n",
    "\n",
    "    # 每个epoch结束后保存模型\n",
    "    model_path = os.path.join(\"FCN_models\", f\"FCN_epoch{epoch+1}.pdparams\")\n",
    "    paddle.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model parameters to {model_path}\")\n",
    "\n",
    "    end_time = time.time()  # 记录epoch结束时间\n",
    "    elapsed_time = end_time - start_time  # 计算epoch的训练时间\n",
    "    print(f\"Epoch {epoch+1} training time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9faf43-4dac-4768-9e12-35e142531036",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0811 23:01:12.277027   806 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.0, Runtime API Version: 11.2\n",
      "W0811 23:01:12.281213   806 device_context.cc:465] device: 0, cuDNN Version: 8.1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model parameters from models/FCN_epoch19.pdparams\n",
      "Epoch 20/60, Batch 1/25, Loss: 0.19643498957157135\n",
      "Epoch 20/60, Batch 2/25, Loss: 0.321828156709671\n",
      "Epoch 20/60, Batch 3/25, Loss: 0.17174826562404633\n",
      "Epoch 20/60, Batch 4/25, Loss: 0.22377492487430573\n",
      "Epoch 20/60, Batch 5/25, Loss: 0.12724143266677856\n",
      "Epoch 20/60, Batch 6/25, Loss: 0.18040204048156738\n",
      "Epoch 20/60, Batch 7/25, Loss: 0.16117048263549805\n",
      "Epoch 20/60, Batch 8/25, Loss: 0.2671787440776825\n",
      "Epoch 20/60, Batch 9/25, Loss: 0.17652735114097595\n",
      "Epoch 20/60, Batch 10/25, Loss: 0.1420547068119049\n",
      "Epoch 20/60, Batch 11/25, Loss: 0.1806362271308899\n",
      "Epoch 20/60, Batch 12/25, Loss: 0.16073061525821686\n",
      "Epoch 20/60, Batch 13/25, Loss: 0.15142333507537842\n",
      "Epoch 20/60, Batch 14/25, Loss: 0.1688186675310135\n",
      "Epoch 20/60, Batch 15/25, Loss: 0.18573909997940063\n",
      "Epoch 20/60, Batch 16/25, Loss: 0.1645476222038269\n",
      "Epoch 20/60, Batch 17/25, Loss: 0.17121979594230652\n",
      "Epoch 20/60, Batch 18/25, Loss: 0.1913444846868515\n",
      "Epoch 20/60, Batch 19/25, Loss: 0.2148149609565735\n",
      "Epoch 20/60, Batch 20/25, Loss: 0.1615150272846222\n",
      "Epoch 20/60, Batch 21/25, Loss: 0.1522940844297409\n",
      "Epoch 20/60, Batch 22/25, Loss: 0.16385293006896973\n",
      "Epoch 20/60, Batch 23/25, Loss: 0.19796331226825714\n",
      "Epoch 20/60, Batch 24/25, Loss: 0.15171635150909424\n",
      "Epoch 20/60, Batch 25/25, Loss: 0.13338914513587952\n",
      "Saved model parameters to models/FCN_epoch20.pdparams\n",
      "Epoch 21/60, Batch 1/25, Loss: 0.1909593790769577\n",
      "Epoch 21/60, Batch 2/25, Loss: 0.14870190620422363\n",
      "Epoch 21/60, Batch 3/25, Loss: 0.14669854938983917\n",
      "Epoch 21/60, Batch 4/25, Loss: 0.14925627410411835\n",
      "Epoch 21/60, Batch 5/25, Loss: 0.1426752507686615\n",
      "Epoch 21/60, Batch 6/25, Loss: 0.153236985206604\n",
      "Epoch 21/60, Batch 7/25, Loss: 0.20333297550678253\n",
      "Epoch 21/60, Batch 8/25, Loss: 0.18446868658065796\n",
      "Epoch 21/60, Batch 9/25, Loss: 0.14593839645385742\n",
      "Epoch 21/60, Batch 10/25, Loss: 0.15888497233390808\n",
      "Epoch 21/60, Batch 11/25, Loss: 0.18456414341926575\n",
      "Epoch 21/60, Batch 12/25, Loss: 0.1699686497449875\n",
      "Epoch 21/60, Batch 13/25, Loss: 0.18108969926834106\n",
      "Epoch 21/60, Batch 14/25, Loss: 0.15459787845611572\n",
      "Epoch 21/60, Batch 15/25, Loss: 0.18898910284042358\n",
      "Epoch 21/60, Batch 16/25, Loss: 0.12273780256509781\n",
      "Epoch 21/60, Batch 17/25, Loss: 0.16995781660079956\n",
      "Epoch 21/60, Batch 18/25, Loss: 0.13866324722766876\n",
      "Epoch 21/60, Batch 19/25, Loss: 0.18335215747356415\n",
      "Epoch 21/60, Batch 20/25, Loss: 0.1724817007780075\n",
      "Epoch 21/60, Batch 21/25, Loss: 0.15091347694396973\n",
      "Epoch 21/60, Batch 22/25, Loss: 0.1158643364906311\n",
      "Epoch 21/60, Batch 23/25, Loss: 0.17060820758342743\n",
      "Epoch 21/60, Batch 24/25, Loss: 0.1780223697423935\n",
      "Epoch 21/60, Batch 25/25, Loss: 0.18663543462753296\n",
      "Saved model parameters to models/FCN_epoch21.pdparams\n",
      "Epoch 22/60, Batch 1/25, Loss: 0.19110308587551117\n",
      "Epoch 22/60, Batch 2/25, Loss: 0.18968136608600616\n",
      "Epoch 22/60, Batch 3/25, Loss: 0.1351493000984192\n",
      "Epoch 22/60, Batch 4/25, Loss: 0.15088552236557007\n",
      "Epoch 22/60, Batch 5/25, Loss: 0.165693461894989\n",
      "Epoch 22/60, Batch 6/25, Loss: 0.1367294192314148\n",
      "Epoch 22/60, Batch 7/25, Loss: 0.14904366433620453\n",
      "Epoch 22/60, Batch 8/25, Loss: 0.14197474718093872\n",
      "Epoch 22/60, Batch 9/25, Loss: 0.1982700228691101\n",
      "Epoch 22/60, Batch 10/25, Loss: 0.13823217153549194\n",
      "Epoch 22/60, Batch 11/25, Loss: 0.13204188644886017\n",
      "Epoch 22/60, Batch 12/25, Loss: 0.20218928158283234\n",
      "Epoch 22/60, Batch 13/25, Loss: 0.1421322077512741\n",
      "Epoch 22/60, Batch 14/25, Loss: 0.1538822501897812\n",
      "Epoch 22/60, Batch 15/25, Loss: 0.18021516501903534\n",
      "Epoch 22/60, Batch 16/25, Loss: 0.15091829001903534\n",
      "Epoch 22/60, Batch 17/25, Loss: 0.12685127556324005\n",
      "Epoch 22/60, Batch 18/25, Loss: 0.14255297183990479\n",
      "Epoch 22/60, Batch 19/25, Loss: 0.1452556997537613\n",
      "Epoch 22/60, Batch 20/25, Loss: 0.16716119647026062\n",
      "Epoch 22/60, Batch 21/25, Loss: 0.21761947870254517\n",
      "Epoch 22/60, Batch 22/25, Loss: 0.1984860599040985\n",
      "Epoch 22/60, Batch 23/25, Loss: 0.14332731068134308\n",
      "Epoch 22/60, Batch 24/25, Loss: 0.14663000404834747\n",
      "Epoch 22/60, Batch 25/25, Loss: 0.1522057056427002\n",
      "Saved model parameters to models/FCN_epoch22.pdparams\n",
      "Epoch 23/60, Batch 1/25, Loss: 0.1415753960609436\n",
      "Epoch 23/60, Batch 2/25, Loss: 0.14382797479629517\n",
      "Epoch 23/60, Batch 3/25, Loss: 0.16262567043304443\n",
      "Epoch 23/60, Batch 4/25, Loss: 0.15167918801307678\n",
      "Epoch 23/60, Batch 5/25, Loss: 0.11974101513624191\n",
      "Epoch 23/60, Batch 6/25, Loss: 0.11650700867176056\n",
      "Epoch 23/60, Batch 7/25, Loss: 0.13272984325885773\n",
      "Epoch 23/60, Batch 8/25, Loss: 0.12377874553203583\n",
      "Epoch 23/60, Batch 9/25, Loss: 0.14835916459560394\n",
      "Epoch 23/60, Batch 10/25, Loss: 0.17449823021888733\n",
      "Epoch 23/60, Batch 11/25, Loss: 0.15639923512935638\n",
      "Epoch 23/60, Batch 12/25, Loss: 0.10862366855144501\n",
      "Epoch 23/60, Batch 13/25, Loss: 0.10414344072341919\n",
      "Epoch 23/60, Batch 14/25, Loss: 0.183964803814888\n",
      "Epoch 23/60, Batch 15/25, Loss: 0.16704776883125305\n",
      "Epoch 23/60, Batch 16/25, Loss: 0.14323602616786957\n",
      "Epoch 23/60, Batch 17/25, Loss: 0.18600359559059143\n",
      "Epoch 23/60, Batch 18/25, Loss: 0.18176989257335663\n",
      "Epoch 23/60, Batch 19/25, Loss: 0.15187601745128632\n",
      "Epoch 23/60, Batch 20/25, Loss: 0.13967476785182953\n",
      "Epoch 23/60, Batch 21/25, Loss: 0.11203602701425552\n",
      "Epoch 23/60, Batch 22/25, Loss: 0.202784463763237\n",
      "Epoch 23/60, Batch 23/25, Loss: 0.10988860577344894\n",
      "Epoch 23/60, Batch 24/25, Loss: 0.2080964595079422\n",
      "Epoch 23/60, Batch 25/25, Loss: 0.15855716168880463\n",
      "Saved model parameters to models/FCN_epoch23.pdparams\n",
      "Epoch 24/60, Batch 1/25, Loss: 0.11233141273260117\n",
      "Epoch 24/60, Batch 2/25, Loss: 0.1525885909795761\n",
      "Epoch 24/60, Batch 3/25, Loss: 0.09691064059734344\n",
      "Epoch 24/60, Batch 4/25, Loss: 0.15841515362262726\n",
      "Epoch 24/60, Batch 5/25, Loss: 0.18174347281455994\n",
      "Epoch 24/60, Batch 6/25, Loss: 0.174910768866539\n",
      "Epoch 24/60, Batch 7/25, Loss: 0.16808274388313293\n",
      "Epoch 24/60, Batch 8/25, Loss: 0.15506447851657867\n",
      "Epoch 24/60, Batch 9/25, Loss: 0.15791332721710205\n",
      "Epoch 24/60, Batch 10/25, Loss: 0.13005352020263672\n",
      "Epoch 24/60, Batch 11/25, Loss: 0.15507476031780243\n",
      "Epoch 24/60, Batch 12/25, Loss: 0.15349441766738892\n",
      "Epoch 24/60, Batch 13/25, Loss: 0.15221694111824036\n",
      "Epoch 24/60, Batch 14/25, Loss: 0.1482449769973755\n",
      "Epoch 24/60, Batch 15/25, Loss: 0.1924290955066681\n",
      "Epoch 24/60, Batch 16/25, Loss: 0.13581925630569458\n",
      "Epoch 24/60, Batch 17/25, Loss: 0.13222265243530273\n",
      "Epoch 24/60, Batch 18/25, Loss: 0.16668903827667236\n",
      "Epoch 24/60, Batch 19/25, Loss: 0.11725111305713654\n",
      "Epoch 24/60, Batch 20/25, Loss: 0.12184728682041168\n",
      "Epoch 24/60, Batch 21/25, Loss: 0.15857286751270294\n",
      "Epoch 24/60, Batch 22/25, Loss: 0.13230422139167786\n",
      "Epoch 24/60, Batch 23/25, Loss: 0.1373043954372406\n",
      "Epoch 24/60, Batch 24/25, Loss: 0.12889334559440613\n",
      "Epoch 24/60, Batch 25/25, Loss: 0.18175679445266724\n",
      "Saved model parameters to models/FCN_epoch24.pdparams\n",
      "Epoch 25/60, Batch 1/25, Loss: 0.13785836100578308\n",
      "Epoch 25/60, Batch 2/25, Loss: 0.13710448145866394\n",
      "Epoch 25/60, Batch 3/25, Loss: 0.1732114851474762\n",
      "Epoch 25/60, Batch 4/25, Loss: 0.12401914596557617\n",
      "Epoch 25/60, Batch 5/25, Loss: 0.1977897435426712\n",
      "Epoch 25/60, Batch 6/25, Loss: 0.1850937306880951\n",
      "Epoch 25/60, Batch 7/25, Loss: 0.19001996517181396\n",
      "Epoch 25/60, Batch 8/25, Loss: 0.117139533162117\n",
      "Epoch 25/60, Batch 9/25, Loss: 0.1319625973701477\n",
      "Epoch 25/60, Batch 10/25, Loss: 0.1557445526123047\n",
      "Epoch 25/60, Batch 11/25, Loss: 0.10310674458742142\n",
      "Epoch 25/60, Batch 12/25, Loss: 0.14776532351970673\n",
      "Epoch 25/60, Batch 13/25, Loss: 0.16925868391990662\n",
      "Epoch 25/60, Batch 14/25, Loss: 0.1466176062822342\n",
      "Epoch 25/60, Batch 15/25, Loss: 0.11776303499937057\n",
      "Epoch 25/60, Batch 16/25, Loss: 0.10853490233421326\n",
      "Epoch 25/60, Batch 17/25, Loss: 0.14900346100330353\n",
      "Epoch 25/60, Batch 18/25, Loss: 0.12989017367362976\n",
      "Epoch 25/60, Batch 19/25, Loss: 0.13556915521621704\n",
      "Epoch 25/60, Batch 20/25, Loss: 0.09155575931072235\n",
      "Epoch 25/60, Batch 21/25, Loss: 0.20614810287952423\n",
      "Epoch 25/60, Batch 22/25, Loss: 0.1120574027299881\n",
      "Epoch 25/60, Batch 23/25, Loss: 0.20462001860141754\n",
      "Epoch 25/60, Batch 24/25, Loss: 0.1407260149717331\n",
      "Epoch 25/60, Batch 25/25, Loss: 0.21998316049575806\n",
      "Saved model parameters to models/FCN_epoch25.pdparams\n",
      "Epoch 26/60, Batch 1/25, Loss: 0.1962449550628662\n",
      "Epoch 26/60, Batch 2/25, Loss: 0.1296190768480301\n",
      "Epoch 26/60, Batch 3/25, Loss: 0.14161701500415802\n",
      "Epoch 26/60, Batch 4/25, Loss: 0.17614543437957764\n",
      "Epoch 26/60, Batch 5/25, Loss: 0.11551041156053543\n",
      "Epoch 26/60, Batch 6/25, Loss: 0.13611865043640137\n",
      "Epoch 26/60, Batch 7/25, Loss: 0.17240284383296967\n",
      "Epoch 26/60, Batch 8/25, Loss: 0.11499784886837006\n",
      "Epoch 26/60, Batch 9/25, Loss: 0.14508354663848877\n",
      "Epoch 26/60, Batch 10/25, Loss: 0.14899536967277527\n",
      "Epoch 26/60, Batch 11/25, Loss: 0.11983773112297058\n",
      "Epoch 26/60, Batch 12/25, Loss: 0.12531796097755432\n",
      "Epoch 26/60, Batch 13/25, Loss: 0.16058142483234406\n",
      "Epoch 26/60, Batch 14/25, Loss: 0.1705213189125061\n",
      "Epoch 26/60, Batch 15/25, Loss: 0.1056426465511322\n",
      "Epoch 26/60, Batch 16/25, Loss: 0.19314995408058167\n",
      "Epoch 26/60, Batch 17/25, Loss: 0.17213056981563568\n",
      "Epoch 26/60, Batch 18/25, Loss: 0.14784251153469086\n",
      "Epoch 26/60, Batch 19/25, Loss: 0.13674235343933105\n",
      "Epoch 26/60, Batch 20/25, Loss: 0.14188995957374573\n",
      "Epoch 26/60, Batch 21/25, Loss: 0.12214288115501404\n",
      "Epoch 26/60, Batch 22/25, Loss: 0.15217329561710358\n",
      "Epoch 26/60, Batch 23/25, Loss: 0.17128975689411163\n",
      "Epoch 26/60, Batch 24/25, Loss: 0.14482499659061432\n",
      "Epoch 26/60, Batch 25/25, Loss: 0.11493523418903351\n",
      "Saved model parameters to models/FCN_epoch26.pdparams\n",
      "Epoch 27/60, Batch 1/25, Loss: 0.17074160277843475\n",
      "Epoch 27/60, Batch 2/25, Loss: 0.12173900008201599\n",
      "Epoch 27/60, Batch 3/25, Loss: 0.1753050684928894\n",
      "Epoch 27/60, Batch 4/25, Loss: 0.17619578540325165\n",
      "Epoch 27/60, Batch 5/25, Loss: 0.10400480031967163\n",
      "Epoch 27/60, Batch 6/25, Loss: 0.16031892597675323\n",
      "Epoch 27/60, Batch 7/25, Loss: 0.14958518743515015\n",
      "Epoch 27/60, Batch 8/25, Loss: 0.1006658673286438\n",
      "Epoch 27/60, Batch 9/25, Loss: 0.12968029081821442\n",
      "Epoch 27/60, Batch 10/25, Loss: 0.11583193391561508\n",
      "Epoch 27/60, Batch 11/25, Loss: 0.10359546542167664\n",
      "Epoch 27/60, Batch 12/25, Loss: 0.1383093297481537\n",
      "Epoch 27/60, Batch 13/25, Loss: 0.16302770376205444\n",
      "Epoch 27/60, Batch 14/25, Loss: 0.14315834641456604\n",
      "Epoch 27/60, Batch 15/25, Loss: 0.2313675880432129\n",
      "Epoch 27/60, Batch 16/25, Loss: 0.11917447298765182\n",
      "Epoch 27/60, Batch 17/25, Loss: 0.0808015987277031\n",
      "Epoch 27/60, Batch 18/25, Loss: 0.15577420592308044\n",
      "Epoch 27/60, Batch 19/25, Loss: 0.19749096035957336\n",
      "Epoch 27/60, Batch 20/25, Loss: 0.1120179146528244\n",
      "Epoch 27/60, Batch 21/25, Loss: 0.1919218748807907\n",
      "Epoch 27/60, Batch 22/25, Loss: 0.13973072171211243\n",
      "Epoch 27/60, Batch 23/25, Loss: 0.0965803861618042\n",
      "Epoch 27/60, Batch 24/25, Loss: 0.16482087969779968\n",
      "Epoch 27/60, Batch 25/25, Loss: 0.1023121029138565\n",
      "Saved model parameters to models/FCN_epoch27.pdparams\n",
      "Epoch 28/60, Batch 1/25, Loss: 0.08539649844169617\n",
      "Epoch 28/60, Batch 2/25, Loss: 0.208811417222023\n",
      "Epoch 28/60, Batch 3/25, Loss: 0.12950482964515686\n",
      "Epoch 28/60, Batch 4/25, Loss: 0.09679058194160461\n",
      "Epoch 28/60, Batch 5/25, Loss: 0.11300459504127502\n",
      "Epoch 28/60, Batch 6/25, Loss: 0.16878816485404968\n",
      "Epoch 28/60, Batch 7/25, Loss: 0.1843339502811432\n",
      "Epoch 28/60, Batch 8/25, Loss: 0.14996537566184998\n",
      "Epoch 28/60, Batch 9/25, Loss: 0.13182072341442108\n",
      "Epoch 28/60, Batch 10/25, Loss: 0.176049143075943\n",
      "Epoch 28/60, Batch 11/25, Loss: 0.1332390457391739\n",
      "Epoch 28/60, Batch 12/25, Loss: 0.16663549840450287\n",
      "Epoch 28/60, Batch 13/25, Loss: 0.11666852235794067\n",
      "Epoch 28/60, Batch 14/25, Loss: 0.09894303232431412\n",
      "Epoch 28/60, Batch 15/25, Loss: 0.11966259032487869\n",
      "Epoch 28/60, Batch 16/25, Loss: 0.19728590548038483\n",
      "Epoch 28/60, Batch 17/25, Loss: 0.13400720059871674\n",
      "Epoch 28/60, Batch 18/25, Loss: 0.12537404894828796\n",
      "Epoch 28/60, Batch 19/25, Loss: 0.15959863364696503\n",
      "Epoch 28/60, Batch 20/25, Loss: 0.16456031799316406\n",
      "Epoch 28/60, Batch 21/25, Loss: 0.12776440382003784\n",
      "Epoch 28/60, Batch 22/25, Loss: 0.17464075982570648\n",
      "Epoch 28/60, Batch 23/25, Loss: 0.09159878641366959\n",
      "Epoch 28/60, Batch 24/25, Loss: 0.13698633015155792\n",
      "Epoch 28/60, Batch 25/25, Loss: 0.14616774022579193\n",
      "Saved model parameters to models/FCN_epoch28.pdparams\n",
      "Epoch 29/60, Batch 1/25, Loss: 0.09836294502019882\n",
      "Epoch 29/60, Batch 2/25, Loss: 0.09103523194789886\n",
      "Epoch 29/60, Batch 3/25, Loss: 0.18404047191143036\n",
      "Epoch 29/60, Batch 4/25, Loss: 0.16266125440597534\n",
      "Epoch 29/60, Batch 5/25, Loss: 0.1578793227672577\n",
      "Epoch 29/60, Batch 6/25, Loss: 0.14748534560203552\n",
      "Epoch 29/60, Batch 7/25, Loss: 0.1667456179857254\n",
      "Epoch 29/60, Batch 8/25, Loss: 0.08083242923021317\n",
      "Epoch 29/60, Batch 9/25, Loss: 0.2132149636745453\n",
      "Epoch 29/60, Batch 10/25, Loss: 0.10301381349563599\n",
      "Epoch 29/60, Batch 11/25, Loss: 0.14701908826828003\n",
      "Epoch 29/60, Batch 12/25, Loss: 0.1782350242137909\n",
      "Epoch 29/60, Batch 13/25, Loss: 0.1423262506723404\n",
      "Epoch 29/60, Batch 14/25, Loss: 0.16053864359855652\n",
      "Epoch 29/60, Batch 15/25, Loss: 0.17137360572814941\n",
      "Epoch 29/60, Batch 16/25, Loss: 0.1504230797290802\n",
      "Epoch 29/60, Batch 17/25, Loss: 0.11818529665470123\n",
      "Epoch 29/60, Batch 18/25, Loss: 0.1646542251110077\n",
      "Epoch 29/60, Batch 19/25, Loss: 0.15145619213581085\n",
      "Epoch 29/60, Batch 20/25, Loss: 0.16112551093101501\n",
      "Epoch 29/60, Batch 21/25, Loss: 0.15605290234088898\n",
      "Epoch 29/60, Batch 22/25, Loss: 0.12566040456295013\n",
      "Epoch 29/60, Batch 23/25, Loss: 0.1509915441274643\n",
      "Epoch 29/60, Batch 24/25, Loss: 0.14127793908119202\n",
      "Epoch 29/60, Batch 25/25, Loss: 0.12332835048437119\n",
      "Saved model parameters to models/FCN_epoch29.pdparams\n",
      "Epoch 30/60, Batch 1/25, Loss: 0.2101532220840454\n",
      "Epoch 30/60, Batch 2/25, Loss: 0.1531321406364441\n",
      "Epoch 30/60, Batch 3/25, Loss: 0.1358526051044464\n",
      "Epoch 30/60, Batch 4/25, Loss: 0.13234369456768036\n",
      "Epoch 30/60, Batch 5/25, Loss: 0.1432162970304489\n",
      "Epoch 30/60, Batch 6/25, Loss: 0.1574753224849701\n",
      "Epoch 30/60, Batch 7/25, Loss: 0.11209999024868011\n",
      "Epoch 30/60, Batch 8/25, Loss: 0.10721024125814438\n",
      "Epoch 30/60, Batch 9/25, Loss: 0.16574791073799133\n",
      "Epoch 30/60, Batch 10/25, Loss: 0.10615431517362595\n",
      "Epoch 30/60, Batch 11/25, Loss: 0.1636015921831131\n",
      "Epoch 30/60, Batch 12/25, Loss: 0.14629019796848297\n",
      "Epoch 30/60, Batch 13/25, Loss: 0.14602825045585632\n",
      "Epoch 30/60, Batch 14/25, Loss: 0.1655423492193222\n",
      "Epoch 30/60, Batch 15/25, Loss: 0.14502514898777008\n",
      "Epoch 30/60, Batch 16/25, Loss: 0.19015562534332275\n",
      "Epoch 30/60, Batch 17/25, Loss: 0.13179823756217957\n",
      "Epoch 30/60, Batch 18/25, Loss: 0.10185230523347855\n",
      "Epoch 30/60, Batch 19/25, Loss: 0.08436219394207001\n",
      "Epoch 30/60, Batch 20/25, Loss: 0.21342220902442932\n",
      "Epoch 30/60, Batch 21/25, Loss: 0.11024093627929688\n",
      "Epoch 30/60, Batch 22/25, Loss: 0.12746083736419678\n",
      "Epoch 30/60, Batch 23/25, Loss: 0.14105065166950226\n",
      "Epoch 30/60, Batch 24/25, Loss: 0.13245299458503723\n",
      "Epoch 30/60, Batch 25/25, Loss: 0.08126344531774521\n",
      "Saved model parameters to models/FCN_epoch30.pdparams\n",
      "Epoch 31/60, Batch 1/25, Loss: 0.10637474060058594\n",
      "Epoch 31/60, Batch 2/25, Loss: 0.13677798211574554\n",
      "Epoch 31/60, Batch 3/25, Loss: 0.11851875483989716\n",
      "Epoch 31/60, Batch 4/25, Loss: 0.1353967934846878\n",
      "Epoch 31/60, Batch 5/25, Loss: 0.10067752748727798\n",
      "Epoch 31/60, Batch 6/25, Loss: 0.12500756978988647\n",
      "Epoch 31/60, Batch 7/25, Loss: 0.19445165991783142\n",
      "Epoch 31/60, Batch 8/25, Loss: 0.10905154049396515\n",
      "Epoch 31/60, Batch 9/25, Loss: 0.110361747443676\n",
      "Epoch 31/60, Batch 10/25, Loss: 0.1425657570362091\n",
      "Epoch 31/60, Batch 11/25, Loss: 0.10388882458209991\n",
      "Epoch 31/60, Batch 12/25, Loss: 0.14254803955554962\n",
      "Epoch 31/60, Batch 13/25, Loss: 0.16296423971652985\n",
      "Epoch 31/60, Batch 14/25, Loss: 0.13139691948890686\n",
      "Epoch 31/60, Batch 15/25, Loss: 0.16597987711429596\n",
      "Epoch 31/60, Batch 16/25, Loss: 0.1795206069946289\n",
      "Epoch 31/60, Batch 17/25, Loss: 0.19294840097427368\n",
      "Epoch 31/60, Batch 18/25, Loss: 0.14712873101234436\n",
      "Epoch 31/60, Batch 19/25, Loss: 0.11415180563926697\n",
      "Epoch 31/60, Batch 20/25, Loss: 0.09150370955467224\n",
      "Epoch 31/60, Batch 21/25, Loss: 0.1247146874666214\n",
      "Epoch 31/60, Batch 22/25, Loss: 0.14803780615329742\n",
      "Epoch 31/60, Batch 23/25, Loss: 0.17822295427322388\n",
      "Epoch 31/60, Batch 24/25, Loss: 0.11829353868961334\n",
      "Epoch 31/60, Batch 25/25, Loss: 0.14055736362934113\n",
      "Saved model parameters to models/FCN_epoch31.pdparams\n",
      "Epoch 32/60, Batch 1/25, Loss: 0.1302037239074707\n",
      "Epoch 32/60, Batch 2/25, Loss: 0.12756599485874176\n",
      "Epoch 32/60, Batch 3/25, Loss: 0.1156211644411087\n",
      "Epoch 32/60, Batch 4/25, Loss: 0.17366474866867065\n",
      "Epoch 32/60, Batch 5/25, Loss: 0.12894169986248016\n",
      "Epoch 32/60, Batch 6/25, Loss: 0.16530168056488037\n",
      "Epoch 32/60, Batch 7/25, Loss: 0.23293112218379974\n",
      "Epoch 32/60, Batch 8/25, Loss: 0.17978119850158691\n",
      "Epoch 32/60, Batch 9/25, Loss: 0.13252849876880646\n",
      "Epoch 32/60, Batch 10/25, Loss: 0.14328789710998535\n",
      "Epoch 32/60, Batch 11/25, Loss: 0.09501059353351593\n",
      "Epoch 32/60, Batch 12/25, Loss: 0.1347765326499939\n",
      "Epoch 32/60, Batch 13/25, Loss: 0.16445335745811462\n",
      "Epoch 32/60, Batch 14/25, Loss: 0.14397281408309937\n",
      "Epoch 32/60, Batch 15/25, Loss: 0.0922568142414093\n",
      "Epoch 32/60, Batch 16/25, Loss: 0.13147088885307312\n",
      "Epoch 32/60, Batch 17/25, Loss: 0.1826428771018982\n",
      "Epoch 32/60, Batch 18/25, Loss: 0.15723443031311035\n",
      "Epoch 32/60, Batch 19/25, Loss: 0.12262164801359177\n",
      "Epoch 32/60, Batch 20/25, Loss: 0.15104073286056519\n",
      "Epoch 32/60, Batch 21/25, Loss: 0.1319238841533661\n",
      "Epoch 32/60, Batch 22/25, Loss: 0.20430368185043335\n",
      "Epoch 32/60, Batch 23/25, Loss: 0.1161613017320633\n",
      "Epoch 32/60, Batch 24/25, Loss: 0.12912192940711975\n",
      "Epoch 32/60, Batch 25/25, Loss: 0.15173578262329102\n",
      "Saved model parameters to models/FCN_epoch32.pdparams\n",
      "Epoch 33/60, Batch 1/25, Loss: 0.11635982990264893\n",
      "Epoch 33/60, Batch 2/25, Loss: 0.10212600231170654\n",
      "Epoch 33/60, Batch 3/25, Loss: 0.16019606590270996\n",
      "Epoch 33/60, Batch 4/25, Loss: 0.17514584958553314\n",
      "Epoch 33/60, Batch 5/25, Loss: 0.2083013504743576\n",
      "Epoch 33/60, Batch 6/25, Loss: 0.16508692502975464\n",
      "Epoch 33/60, Batch 7/25, Loss: 0.18316078186035156\n",
      "Epoch 33/60, Batch 8/25, Loss: 0.14191775023937225\n",
      "Epoch 33/60, Batch 9/25, Loss: 0.1416987180709839\n",
      "Epoch 33/60, Batch 10/25, Loss: 0.13828124105930328\n",
      "Epoch 33/60, Batch 11/25, Loss: 0.11800342798233032\n",
      "Epoch 33/60, Batch 12/25, Loss: 0.14832359552383423\n",
      "Epoch 33/60, Batch 13/25, Loss: 0.10664384067058563\n",
      "Epoch 33/60, Batch 14/25, Loss: 0.13244791328907013\n",
      "Epoch 33/60, Batch 15/25, Loss: 0.220699280500412\n",
      "Epoch 33/60, Batch 16/25, Loss: 0.12270048260688782\n",
      "Epoch 33/60, Batch 17/25, Loss: 0.1441848874092102\n",
      "Epoch 33/60, Batch 18/25, Loss: 0.09242606163024902\n",
      "Epoch 33/60, Batch 19/25, Loss: 0.17483638226985931\n",
      "Epoch 33/60, Batch 20/25, Loss: 0.17091959714889526\n",
      "Epoch 33/60, Batch 21/25, Loss: 0.18063755333423615\n",
      "Epoch 33/60, Batch 22/25, Loss: 0.17947064340114594\n",
      "Epoch 33/60, Batch 23/25, Loss: 0.13640251755714417\n",
      "Epoch 33/60, Batch 24/25, Loss: 0.12862125039100647\n",
      "Epoch 33/60, Batch 25/25, Loss: 0.12055688351392746\n",
      "Saved model parameters to models/FCN_epoch33.pdparams\n",
      "Epoch 34/60, Batch 1/25, Loss: 0.1787562370300293\n",
      "Epoch 34/60, Batch 2/25, Loss: 0.15819719433784485\n",
      "Epoch 34/60, Batch 3/25, Loss: 0.14980919659137726\n",
      "Epoch 34/60, Batch 4/25, Loss: 0.17310500144958496\n",
      "Epoch 34/60, Batch 5/25, Loss: 0.10606949031352997\n",
      "Epoch 34/60, Batch 6/25, Loss: 0.1111496090888977\n",
      "Epoch 34/60, Batch 7/25, Loss: 0.13460861146450043\n",
      "Epoch 34/60, Batch 8/25, Loss: 0.15096744894981384\n",
      "Epoch 34/60, Batch 9/25, Loss: 0.15318942070007324\n",
      "Epoch 34/60, Batch 10/25, Loss: 0.1521817445755005\n",
      "Epoch 34/60, Batch 11/25, Loss: 0.17034472525119781\n",
      "Epoch 34/60, Batch 12/25, Loss: 0.17826856672763824\n",
      "Epoch 34/60, Batch 13/25, Loss: 0.12308807671070099\n",
      "Epoch 34/60, Batch 14/25, Loss: 0.10183387994766235\n",
      "Epoch 34/60, Batch 15/25, Loss: 0.1683282107114792\n",
      "Epoch 34/60, Batch 16/25, Loss: 0.11311735957860947\n",
      "Epoch 34/60, Batch 17/25, Loss: 0.12375684082508087\n",
      "Epoch 34/60, Batch 18/25, Loss: 0.10364019125699997\n",
      "Epoch 34/60, Batch 19/25, Loss: 0.16119641065597534\n",
      "Epoch 34/60, Batch 20/25, Loss: 0.12314124405384064\n",
      "Epoch 34/60, Batch 21/25, Loss: 0.09699354320764542\n",
      "Epoch 34/60, Batch 22/25, Loss: 0.16695791482925415\n",
      "Epoch 34/60, Batch 23/25, Loss: 0.11635477840900421\n",
      "Epoch 34/60, Batch 24/25, Loss: 0.11057357490062714\n",
      "Epoch 34/60, Batch 25/25, Loss: 0.19056610763072968\n",
      "Saved model parameters to models/FCN_epoch34.pdparams\n",
      "Epoch 35/60, Batch 1/25, Loss: 0.1726388782262802\n",
      "Epoch 35/60, Batch 2/25, Loss: 0.14934313297271729\n",
      "Epoch 35/60, Batch 3/25, Loss: 0.11891476809978485\n",
      "Epoch 35/60, Batch 4/25, Loss: 0.19329217076301575\n",
      "Epoch 35/60, Batch 5/25, Loss: 0.1057075560092926\n",
      "Epoch 35/60, Batch 6/25, Loss: 0.1394425332546234\n",
      "Epoch 35/60, Batch 7/25, Loss: 0.13081026077270508\n",
      "Epoch 35/60, Batch 8/25, Loss: 0.12139204144477844\n",
      "Epoch 35/60, Batch 9/25, Loss: 0.14431896805763245\n",
      "Epoch 35/60, Batch 10/25, Loss: 0.13511021435260773\n",
      "Epoch 35/60, Batch 11/25, Loss: 0.11044763028621674\n",
      "Epoch 35/60, Batch 12/25, Loss: 0.10516917705535889\n",
      "Epoch 35/60, Batch 13/25, Loss: 0.12111522257328033\n",
      "Epoch 35/60, Batch 14/25, Loss: 0.20297402143478394\n",
      "Epoch 35/60, Batch 15/25, Loss: 0.07690004259347916\n",
      "Epoch 35/60, Batch 16/25, Loss: 0.12672120332717896\n",
      "Epoch 35/60, Batch 17/25, Loss: 0.09665989130735397\n",
      "Epoch 35/60, Batch 18/25, Loss: 0.19742608070373535\n",
      "Epoch 35/60, Batch 19/25, Loss: 0.13124603033065796\n",
      "Epoch 35/60, Batch 20/25, Loss: 0.12046011537313461\n",
      "Epoch 35/60, Batch 21/25, Loss: 0.176489919424057\n",
      "Epoch 35/60, Batch 22/25, Loss: 0.11366432905197144\n",
      "Epoch 35/60, Batch 23/25, Loss: 0.10045932233333588\n",
      "Epoch 35/60, Batch 24/25, Loss: 0.16624568402767181\n",
      "Epoch 35/60, Batch 25/25, Loss: 0.11643965542316437\n",
      "Saved model parameters to models/FCN_epoch35.pdparams\n",
      "Epoch 36/60, Batch 1/25, Loss: 0.10609748959541321\n",
      "Epoch 36/60, Batch 2/25, Loss: 0.1708051711320877\n",
      "Epoch 36/60, Batch 3/25, Loss: 0.12361309677362442\n",
      "Epoch 36/60, Batch 4/25, Loss: 0.11759611964225769\n",
      "Epoch 36/60, Batch 5/25, Loss: 0.1545223742723465\n",
      "Epoch 36/60, Batch 6/25, Loss: 0.13875213265419006\n",
      "Epoch 36/60, Batch 7/25, Loss: 0.10710375010967255\n",
      "Epoch 36/60, Batch 8/25, Loss: 0.12373494356870651\n",
      "Epoch 36/60, Batch 9/25, Loss: 0.14640693366527557\n",
      "Epoch 36/60, Batch 10/25, Loss: 0.12142314016819\n",
      "Epoch 36/60, Batch 11/25, Loss: 0.12033765017986298\n",
      "Epoch 36/60, Batch 12/25, Loss: 0.11353279650211334\n",
      "Epoch 36/60, Batch 13/25, Loss: 0.09591812640428543\n",
      "Epoch 36/60, Batch 14/25, Loss: 0.18074803054332733\n",
      "Epoch 36/60, Batch 15/25, Loss: 0.13765886425971985\n",
      "Epoch 36/60, Batch 16/25, Loss: 0.13531245291233063\n",
      "Epoch 36/60, Batch 17/25, Loss: 0.1568455994129181\n",
      "Epoch 36/60, Batch 18/25, Loss: 0.13653036952018738\n",
      "Epoch 36/60, Batch 19/25, Loss: 0.11167120188474655\n",
      "Epoch 36/60, Batch 20/25, Loss: 0.1108270138502121\n",
      "Epoch 36/60, Batch 21/25, Loss: 0.13364028930664062\n",
      "Epoch 36/60, Batch 22/25, Loss: 0.1422828882932663\n",
      "Epoch 36/60, Batch 23/25, Loss: 0.11196375638246536\n",
      "Epoch 36/60, Batch 24/25, Loss: 0.14086046814918518\n",
      "Epoch 36/60, Batch 25/25, Loss: 0.19929073750972748\n",
      "Saved model parameters to models/FCN_epoch36.pdparams\n",
      "Epoch 37/60, Batch 1/25, Loss: 0.14982712268829346\n",
      "Epoch 37/60, Batch 2/25, Loss: 0.1339149922132492\n",
      "Epoch 37/60, Batch 3/25, Loss: 0.10827937722206116\n",
      "Epoch 37/60, Batch 4/25, Loss: 0.12823383510112762\n",
      "Epoch 37/60, Batch 5/25, Loss: 0.16932740807533264\n",
      "Epoch 37/60, Batch 6/25, Loss: 0.17977997660636902\n",
      "Epoch 37/60, Batch 7/25, Loss: 0.11699864268302917\n",
      "Epoch 37/60, Batch 8/25, Loss: 0.13843272626399994\n",
      "Epoch 37/60, Batch 9/25, Loss: 0.08489346504211426\n",
      "Epoch 37/60, Batch 10/25, Loss: 0.12148508429527283\n",
      "Epoch 37/60, Batch 11/25, Loss: 0.17500638961791992\n",
      "Epoch 37/60, Batch 12/25, Loss: 0.18523357808589935\n",
      "Epoch 37/60, Batch 13/25, Loss: 0.1169753447175026\n",
      "Epoch 37/60, Batch 14/25, Loss: 0.09996845573186874\n",
      "Epoch 37/60, Batch 15/25, Loss: 0.13272088766098022\n",
      "Epoch 37/60, Batch 16/25, Loss: 0.11628003418445587\n",
      "Epoch 37/60, Batch 17/25, Loss: 0.15616968274116516\n",
      "Epoch 37/60, Batch 18/25, Loss: 0.11893867701292038\n",
      "Epoch 37/60, Batch 19/25, Loss: 0.1056775227189064\n",
      "Epoch 37/60, Batch 20/25, Loss: 0.14087337255477905\n",
      "Epoch 37/60, Batch 21/25, Loss: 0.11637460440397263\n",
      "Epoch 37/60, Batch 22/25, Loss: 0.11944406479597092\n",
      "Epoch 37/60, Batch 23/25, Loss: 0.10366924852132797\n",
      "Epoch 37/60, Batch 24/25, Loss: 0.19154490530490875\n",
      "Epoch 37/60, Batch 25/25, Loss: 0.12260022014379501\n",
      "Saved model parameters to models/FCN_epoch37.pdparams\n",
      "Epoch 38/60, Batch 1/25, Loss: 0.19304119050502777\n",
      "Epoch 38/60, Batch 2/25, Loss: 0.11675775051116943\n",
      "Epoch 38/60, Batch 3/25, Loss: 0.10085690766572952\n",
      "Epoch 38/60, Batch 4/25, Loss: 0.12628301978111267\n",
      "Epoch 38/60, Batch 5/25, Loss: 0.13217557966709137\n",
      "Epoch 38/60, Batch 6/25, Loss: 0.1821863204240799\n",
      "Epoch 38/60, Batch 7/25, Loss: 0.07934565842151642\n",
      "Epoch 38/60, Batch 8/25, Loss: 0.14430569112300873\n",
      "Epoch 38/60, Batch 9/25, Loss: 0.1726018488407135\n",
      "Epoch 38/60, Batch 10/25, Loss: 0.13065370917320251\n",
      "Epoch 38/60, Batch 11/25, Loss: 0.12971071898937225\n",
      "Epoch 38/60, Batch 12/25, Loss: 0.13811667263507843\n",
      "Epoch 38/60, Batch 13/25, Loss: 0.14551882445812225\n",
      "Epoch 38/60, Batch 14/25, Loss: 0.06281399726867676\n",
      "Epoch 38/60, Batch 15/25, Loss: 0.14089779555797577\n",
      "Epoch 38/60, Batch 16/25, Loss: 0.17542418837547302\n",
      "Epoch 38/60, Batch 17/25, Loss: 0.10383514314889908\n",
      "Epoch 38/60, Batch 18/25, Loss: 0.0978718101978302\n",
      "Epoch 38/60, Batch 19/25, Loss: 0.14906412363052368\n",
      "Epoch 38/60, Batch 20/25, Loss: 0.09441229701042175\n",
      "Epoch 38/60, Batch 21/25, Loss: 0.13682109117507935\n",
      "Epoch 38/60, Batch 22/25, Loss: 0.13327409327030182\n",
      "Epoch 38/60, Batch 23/25, Loss: 0.11096586287021637\n",
      "Epoch 38/60, Batch 24/25, Loss: 0.09654957056045532\n",
      "Epoch 38/60, Batch 25/25, Loss: 0.1846204549074173\n",
      "Saved model parameters to models/FCN_epoch38.pdparams\n",
      "Epoch 39/60, Batch 1/25, Loss: 0.12845179438591003\n",
      "Epoch 39/60, Batch 2/25, Loss: 0.14354686439037323\n",
      "Epoch 39/60, Batch 3/25, Loss: 0.17067062854766846\n",
      "Epoch 39/60, Batch 4/25, Loss: 0.11448594927787781\n",
      "Epoch 39/60, Batch 5/25, Loss: 0.1382017880678177\n",
      "Epoch 39/60, Batch 6/25, Loss: 0.10589511692523956\n",
      "Epoch 39/60, Batch 7/25, Loss: 0.10924875736236572\n",
      "Epoch 39/60, Batch 8/25, Loss: 0.11777538806200027\n",
      "Epoch 39/60, Batch 9/25, Loss: 0.10885452479124069\n",
      "Epoch 39/60, Batch 10/25, Loss: 0.19767360389232635\n",
      "Epoch 39/60, Batch 11/25, Loss: 0.147152841091156\n",
      "Epoch 39/60, Batch 12/25, Loss: 0.12178938090801239\n",
      "Epoch 39/60, Batch 13/25, Loss: 0.11300422996282578\n",
      "Epoch 39/60, Batch 14/25, Loss: 0.08816765248775482\n",
      "Epoch 39/60, Batch 15/25, Loss: 0.11691433191299438\n",
      "Epoch 39/60, Batch 16/25, Loss: 0.11639387905597687\n",
      "Epoch 39/60, Batch 17/25, Loss: 0.10698263347148895\n",
      "Epoch 39/60, Batch 18/25, Loss: 0.12288809567689896\n",
      "Epoch 39/60, Batch 19/25, Loss: 0.14227744936943054\n",
      "Epoch 39/60, Batch 20/25, Loss: 0.1405903548002243\n",
      "Epoch 39/60, Batch 21/25, Loss: 0.16686366498470306\n",
      "Epoch 39/60, Batch 22/25, Loss: 0.16111518442630768\n",
      "Epoch 39/60, Batch 23/25, Loss: 0.18624049425125122\n",
      "Epoch 39/60, Batch 24/25, Loss: 0.13354595005512238\n",
      "Epoch 39/60, Batch 25/25, Loss: 0.16678276658058167\n",
      "Saved model parameters to models/FCN_epoch39.pdparams\n",
      "Epoch 40/60, Batch 1/25, Loss: 0.14747948944568634\n",
      "Epoch 40/60, Batch 2/25, Loss: 0.09758356958627701\n",
      "Epoch 40/60, Batch 3/25, Loss: 0.15403474867343903\n",
      "Epoch 40/60, Batch 4/25, Loss: 0.15396006405353546\n",
      "Epoch 40/60, Batch 5/25, Loss: 0.11461402475833893\n",
      "Epoch 40/60, Batch 6/25, Loss: 0.11422193050384521\n",
      "Epoch 40/60, Batch 7/25, Loss: 0.123924620449543\n",
      "Epoch 40/60, Batch 8/25, Loss: 0.12392756342887878\n",
      "Epoch 40/60, Batch 9/25, Loss: 0.12434173375368118\n",
      "Epoch 40/60, Batch 10/25, Loss: 0.137835294008255\n",
      "Epoch 40/60, Batch 11/25, Loss: 0.11349170655012131\n",
      "Epoch 40/60, Batch 12/25, Loss: 0.13528165221214294\n",
      "Epoch 40/60, Batch 13/25, Loss: 0.1462540328502655\n",
      "Epoch 40/60, Batch 14/25, Loss: 0.14713889360427856\n",
      "Epoch 40/60, Batch 15/25, Loss: 0.1776164472103119\n",
      "Epoch 40/60, Batch 16/25, Loss: 0.1114106997847557\n",
      "Epoch 40/60, Batch 17/25, Loss: 0.09707938879728317\n",
      "Epoch 40/60, Batch 18/25, Loss: 0.1524585634469986\n",
      "Epoch 40/60, Batch 19/25, Loss: 0.11976665258407593\n",
      "Epoch 40/60, Batch 20/25, Loss: 0.16709004342556\n",
      "Epoch 40/60, Batch 21/25, Loss: 0.14122027158737183\n",
      "Epoch 40/60, Batch 22/25, Loss: 0.14213410019874573\n",
      "Epoch 40/60, Batch 23/25, Loss: 0.14392739534378052\n",
      "Epoch 40/60, Batch 24/25, Loss: 0.14598028361797333\n",
      "Epoch 40/60, Batch 25/25, Loss: 0.11260082572698593\n",
      "Saved model parameters to models/FCN_epoch40.pdparams\n",
      "Epoch 41/60, Batch 1/25, Loss: 0.09018293768167496\n",
      "Epoch 41/60, Batch 2/25, Loss: 0.11325892060995102\n",
      "Epoch 41/60, Batch 3/25, Loss: 0.17570814490318298\n",
      "Epoch 41/60, Batch 4/25, Loss: 0.11098945885896683\n",
      "Epoch 41/60, Batch 5/25, Loss: 0.12011204659938812\n",
      "Epoch 41/60, Batch 6/25, Loss: 0.17860960960388184\n",
      "Epoch 41/60, Batch 7/25, Loss: 0.11032091081142426\n",
      "Epoch 41/60, Batch 8/25, Loss: 0.13565786182880402\n",
      "Epoch 41/60, Batch 9/25, Loss: 0.1708778440952301\n",
      "Epoch 41/60, Batch 10/25, Loss: 0.18358232080936432\n",
      "Epoch 41/60, Batch 11/25, Loss: 0.14332851767539978\n",
      "Epoch 41/60, Batch 12/25, Loss: 0.12694033980369568\n",
      "Epoch 41/60, Batch 13/25, Loss: 0.1414615958929062\n",
      "Epoch 41/60, Batch 14/25, Loss: 0.15073725581169128\n",
      "Epoch 41/60, Batch 15/25, Loss: 0.12870343029499054\n",
      "Epoch 41/60, Batch 16/25, Loss: 0.10513712465763092\n",
      "Epoch 41/60, Batch 17/25, Loss: 0.16725566983222961\n",
      "Epoch 41/60, Batch 18/25, Loss: 0.13780540227890015\n",
      "Epoch 41/60, Batch 19/25, Loss: 0.12758386135101318\n",
      "Epoch 41/60, Batch 20/25, Loss: 0.1302867829799652\n",
      "Epoch 41/60, Batch 21/25, Loss: 0.17073819041252136\n",
      "Epoch 41/60, Batch 22/25, Loss: 0.08476551622152328\n",
      "Epoch 41/60, Batch 23/25, Loss: 0.12650249898433685\n",
      "Epoch 41/60, Batch 24/25, Loss: 0.11455865204334259\n",
      "Epoch 41/60, Batch 25/25, Loss: 0.12398350983858109\n",
      "Saved model parameters to models/FCN_epoch41.pdparams\n",
      "Epoch 42/60, Batch 1/25, Loss: 0.12598669528961182\n",
      "Epoch 42/60, Batch 2/25, Loss: 0.16870275139808655\n",
      "Epoch 42/60, Batch 3/25, Loss: 0.17598462104797363\n",
      "Epoch 42/60, Batch 4/25, Loss: 0.17174331843852997\n",
      "Epoch 42/60, Batch 5/25, Loss: 0.1183556616306305\n",
      "Epoch 42/60, Batch 6/25, Loss: 0.1342363804578781\n",
      "Epoch 42/60, Batch 7/25, Loss: 0.12224175781011581\n",
      "Epoch 42/60, Batch 8/25, Loss: 0.11113866418600082\n",
      "Epoch 42/60, Batch 9/25, Loss: 0.1126311793923378\n",
      "Epoch 42/60, Batch 10/25, Loss: 0.14559371769428253\n",
      "Epoch 42/60, Batch 11/25, Loss: 0.1485084742307663\n",
      "Epoch 42/60, Batch 12/25, Loss: 0.18196731805801392\n",
      "Epoch 42/60, Batch 13/25, Loss: 0.10258713364601135\n",
      "Epoch 42/60, Batch 14/25, Loss: 0.1209927648305893\n",
      "Epoch 42/60, Batch 15/25, Loss: 0.17032727599143982\n",
      "Epoch 42/60, Batch 16/25, Loss: 0.11580437421798706\n",
      "Epoch 42/60, Batch 17/25, Loss: 0.14001554250717163\n",
      "Epoch 42/60, Batch 18/25, Loss: 0.09902962297201157\n",
      "Epoch 42/60, Batch 19/25, Loss: 0.15275666117668152\n",
      "Epoch 42/60, Batch 20/25, Loss: 0.12159209698438644\n",
      "Epoch 42/60, Batch 21/25, Loss: 0.0828637108206749\n",
      "Epoch 42/60, Batch 22/25, Loss: 0.13812482357025146\n",
      "Epoch 42/60, Batch 23/25, Loss: 0.11576832830905914\n",
      "Epoch 42/60, Batch 24/25, Loss: 0.21195088326931\n",
      "Epoch 42/60, Batch 25/25, Loss: 0.13724559545516968\n",
      "Saved model parameters to models/FCN_epoch42.pdparams\n",
      "Epoch 43/60, Batch 1/25, Loss: 0.1426699459552765\n",
      "Epoch 43/60, Batch 2/25, Loss: 0.15493901073932648\n",
      "Epoch 43/60, Batch 3/25, Loss: 0.11310609430074692\n",
      "Epoch 43/60, Batch 4/25, Loss: 0.12553498148918152\n",
      "Epoch 43/60, Batch 5/25, Loss: 0.06538891047239304\n",
      "Epoch 43/60, Batch 6/25, Loss: 0.14799828827381134\n",
      "Epoch 43/60, Batch 7/25, Loss: 0.15655598044395447\n",
      "Epoch 43/60, Batch 8/25, Loss: 0.14521466195583344\n",
      "Epoch 43/60, Batch 9/25, Loss: 0.12486034631729126\n",
      "Epoch 43/60, Batch 10/25, Loss: 0.14580614864826202\n",
      "Epoch 43/60, Batch 11/25, Loss: 0.09920116513967514\n",
      "Epoch 43/60, Batch 12/25, Loss: 0.12332050502300262\n",
      "Epoch 43/60, Batch 13/25, Loss: 0.09930667281150818\n",
      "Epoch 43/60, Batch 14/25, Loss: 0.14781178534030914\n",
      "Epoch 43/60, Batch 15/25, Loss: 0.21342867612838745\n",
      "Epoch 43/60, Batch 16/25, Loss: 0.15879207849502563\n",
      "Epoch 43/60, Batch 17/25, Loss: 0.11427456140518188\n",
      "Epoch 43/60, Batch 18/25, Loss: 0.13920529186725616\n",
      "Epoch 43/60, Batch 19/25, Loss: 0.15871968865394592\n",
      "Epoch 43/60, Batch 20/25, Loss: 0.17590850591659546\n",
      "Epoch 43/60, Batch 21/25, Loss: 0.11425801366567612\n",
      "Epoch 43/60, Batch 22/25, Loss: 0.10828746855258942\n",
      "Epoch 43/60, Batch 23/25, Loss: 0.1429538130760193\n",
      "Epoch 43/60, Batch 24/25, Loss: 0.10865779966115952\n",
      "Epoch 43/60, Batch 25/25, Loss: 0.17743849754333496\n",
      "Saved model parameters to models/FCN_epoch43.pdparams\n",
      "Epoch 44/60, Batch 1/25, Loss: 0.13145595788955688\n",
      "Epoch 44/60, Batch 2/25, Loss: 0.09799393266439438\n",
      "Epoch 44/60, Batch 3/25, Loss: 0.0944603830575943\n",
      "Epoch 44/60, Batch 4/25, Loss: 0.10927244275808334\n",
      "Epoch 44/60, Batch 5/25, Loss: 0.1437913477420807\n",
      "Epoch 44/60, Batch 6/25, Loss: 0.12422918528318405\n",
      "Epoch 44/60, Batch 7/25, Loss: 0.12558814883232117\n",
      "Epoch 44/60, Batch 8/25, Loss: 0.09625159204006195\n",
      "Epoch 44/60, Batch 9/25, Loss: 0.17500630021095276\n",
      "Epoch 44/60, Batch 10/25, Loss: 0.1957191824913025\n",
      "Epoch 44/60, Batch 11/25, Loss: 0.12777015566825867\n",
      "Epoch 44/60, Batch 12/25, Loss: 0.0978749692440033\n",
      "Epoch 44/60, Batch 13/25, Loss: 0.1076667457818985\n",
      "Epoch 44/60, Batch 14/25, Loss: 0.1255185902118683\n",
      "Epoch 44/60, Batch 15/25, Loss: 0.13716797530651093\n",
      "Epoch 44/60, Batch 16/25, Loss: 0.09302873909473419\n",
      "Epoch 44/60, Batch 17/25, Loss: 0.17856065928936005\n",
      "Epoch 44/60, Batch 18/25, Loss: 0.13203302025794983\n",
      "Epoch 44/60, Batch 19/25, Loss: 0.14587564766407013\n",
      "Epoch 44/60, Batch 20/25, Loss: 0.10932433605194092\n",
      "Epoch 44/60, Batch 21/25, Loss: 0.11136994510889053\n",
      "Epoch 44/60, Batch 22/25, Loss: 0.17601370811462402\n",
      "Epoch 44/60, Batch 23/25, Loss: 0.16065792739391327\n",
      "Epoch 44/60, Batch 24/25, Loss: 0.16319219768047333\n",
      "Epoch 44/60, Batch 25/25, Loss: 0.135657399892807\n",
      "Saved model parameters to models/FCN_epoch44.pdparams\n",
      "Epoch 45/60, Batch 1/25, Loss: 0.12228503078222275\n",
      "Epoch 45/60, Batch 2/25, Loss: 0.11716865748167038\n",
      "Epoch 45/60, Batch 3/25, Loss: 0.11670281738042831\n",
      "Epoch 45/60, Batch 4/25, Loss: 0.15535807609558105\n",
      "Epoch 45/60, Batch 5/25, Loss: 0.09965924173593521\n",
      "Epoch 45/60, Batch 6/25, Loss: 0.09319063276052475\n",
      "Epoch 45/60, Batch 7/25, Loss: 0.1049419641494751\n",
      "Epoch 45/60, Batch 8/25, Loss: 0.15616151690483093\n",
      "Epoch 45/60, Batch 9/25, Loss: 0.1058938130736351\n",
      "Epoch 45/60, Batch 10/25, Loss: 0.13290800154209137\n",
      "Epoch 45/60, Batch 11/25, Loss: 0.08117569237947464\n",
      "Epoch 45/60, Batch 12/25, Loss: 0.1277933269739151\n",
      "Epoch 45/60, Batch 13/25, Loss: 0.1710989624261856\n",
      "Epoch 45/60, Batch 14/25, Loss: 0.1484009325504303\n",
      "Epoch 45/60, Batch 15/25, Loss: 0.10311002284288406\n",
      "Epoch 45/60, Batch 16/25, Loss: 0.14229430258274078\n",
      "Epoch 45/60, Batch 17/25, Loss: 0.1401054412126541\n",
      "Epoch 45/60, Batch 18/25, Loss: 0.18978597223758698\n",
      "Epoch 45/60, Batch 19/25, Loss: 0.1766439527273178\n",
      "Epoch 45/60, Batch 20/25, Loss: 0.1318790316581726\n",
      "Epoch 45/60, Batch 21/25, Loss: 0.1239769235253334\n",
      "Epoch 45/60, Batch 22/25, Loss: 0.1500340700149536\n",
      "Epoch 45/60, Batch 23/25, Loss: 0.12883885204792023\n",
      "Epoch 45/60, Batch 24/25, Loss: 0.11987701803445816\n",
      "Epoch 45/60, Batch 25/25, Loss: 0.13242734968662262\n",
      "Saved model parameters to models/FCN_epoch45.pdparams\n",
      "Epoch 46/60, Batch 1/25, Loss: 0.1571035534143448\n",
      "Epoch 46/60, Batch 2/25, Loss: 0.12695829570293427\n",
      "Epoch 46/60, Batch 3/25, Loss: 0.15823036432266235\n",
      "Epoch 46/60, Batch 4/25, Loss: 0.1283174753189087\n",
      "Epoch 46/60, Batch 5/25, Loss: 0.14489957690238953\n",
      "Epoch 46/60, Batch 6/25, Loss: 0.12944352626800537\n",
      "Epoch 46/60, Batch 7/25, Loss: 0.1425246298313141\n",
      "Epoch 46/60, Batch 8/25, Loss: 0.14598973095417023\n",
      "Epoch 46/60, Batch 9/25, Loss: 0.12519367039203644\n",
      "Epoch 46/60, Batch 10/25, Loss: 0.134591743350029\n",
      "Epoch 46/60, Batch 11/25, Loss: 0.12034090608358383\n",
      "Epoch 46/60, Batch 12/25, Loss: 0.09533283114433289\n",
      "Epoch 46/60, Batch 13/25, Loss: 0.14919649064540863\n",
      "Epoch 46/60, Batch 14/25, Loss: 0.154017373919487\n",
      "Epoch 46/60, Batch 15/25, Loss: 0.16903528571128845\n",
      "Epoch 46/60, Batch 16/25, Loss: 0.16602157056331635\n",
      "Epoch 46/60, Batch 17/25, Loss: 0.12574315071105957\n",
      "Epoch 46/60, Batch 18/25, Loss: 0.1332697570323944\n",
      "Epoch 46/60, Batch 19/25, Loss: 0.11071369051933289\n",
      "Epoch 46/60, Batch 20/25, Loss: 0.08405507355928421\n",
      "Epoch 46/60, Batch 21/25, Loss: 0.10830666869878769\n",
      "Epoch 46/60, Batch 22/25, Loss: 0.1356673538684845\n",
      "Epoch 46/60, Batch 23/25, Loss: 0.11331389099359512\n",
      "Epoch 46/60, Batch 24/25, Loss: 0.06677395105361938\n",
      "Epoch 46/60, Batch 25/25, Loss: 0.09971009939908981\n",
      "Saved model parameters to models/FCN_epoch46.pdparams\n",
      "Epoch 47/60, Batch 1/25, Loss: 0.17129556834697723\n",
      "Epoch 47/60, Batch 2/25, Loss: 0.15502099692821503\n",
      "Epoch 47/60, Batch 3/25, Loss: 0.1522737741470337\n",
      "Epoch 47/60, Batch 4/25, Loss: 0.1697673350572586\n",
      "Epoch 47/60, Batch 5/25, Loss: 0.1187906414270401\n",
      "Epoch 47/60, Batch 6/25, Loss: 0.09212084114551544\n",
      "Epoch 47/60, Batch 7/25, Loss: 0.09296128898859024\n",
      "Epoch 47/60, Batch 8/25, Loss: 0.09826051443815231\n",
      "Epoch 47/60, Batch 9/25, Loss: 0.1336766630411148\n",
      "Epoch 47/60, Batch 10/25, Loss: 0.10110741853713989\n",
      "Epoch 47/60, Batch 11/25, Loss: 0.12397858500480652\n",
      "Epoch 47/60, Batch 12/25, Loss: 0.11523087322711945\n",
      "Epoch 47/60, Batch 13/25, Loss: 0.1113947182893753\n",
      "Epoch 47/60, Batch 14/25, Loss: 0.14276035130023956\n",
      "Epoch 47/60, Batch 15/25, Loss: 0.13530629873275757\n",
      "Epoch 47/60, Batch 16/25, Loss: 0.20073644816875458\n",
      "Epoch 47/60, Batch 17/25, Loss: 0.1272391378879547\n",
      "Epoch 47/60, Batch 18/25, Loss: 0.11011025309562683\n",
      "Epoch 47/60, Batch 19/25, Loss: 0.1588115692138672\n",
      "Epoch 47/60, Batch 20/25, Loss: 0.1183936670422554\n",
      "Epoch 47/60, Batch 21/25, Loss: 0.12042531371116638\n",
      "Epoch 47/60, Batch 22/25, Loss: 0.13668879866600037\n",
      "Epoch 47/60, Batch 23/25, Loss: 0.1017281636595726\n",
      "Epoch 47/60, Batch 24/25, Loss: 0.133000448346138\n",
      "Epoch 47/60, Batch 25/25, Loss: 0.1387520730495453\n",
      "Saved model parameters to models/FCN_epoch47.pdparams\n",
      "Epoch 48/60, Batch 1/25, Loss: 0.12818224728107452\n",
      "Epoch 48/60, Batch 2/25, Loss: 0.14522212743759155\n",
      "Epoch 48/60, Batch 3/25, Loss: 0.10628386586904526\n",
      "Epoch 48/60, Batch 4/25, Loss: 0.10681915283203125\n",
      "Epoch 48/60, Batch 5/25, Loss: 0.18705996870994568\n",
      "Epoch 48/60, Batch 6/25, Loss: 0.062035854905843735\n",
      "Epoch 48/60, Batch 7/25, Loss: 0.1620703935623169\n",
      "Epoch 48/60, Batch 8/25, Loss: 0.09235680103302002\n",
      "Epoch 48/60, Batch 9/25, Loss: 0.08638589084148407\n",
      "Epoch 48/60, Batch 10/25, Loss: 0.09349164366722107\n",
      "Epoch 48/60, Batch 11/25, Loss: 0.11288511753082275\n",
      "Epoch 48/60, Batch 12/25, Loss: 0.06353694200515747\n",
      "Epoch 48/60, Batch 13/25, Loss: 0.24004465341567993\n",
      "Epoch 48/60, Batch 14/25, Loss: 0.13450852036476135\n",
      "Epoch 48/60, Batch 15/25, Loss: 0.13018617033958435\n",
      "Epoch 48/60, Batch 16/25, Loss: 0.1406254917383194\n",
      "Epoch 48/60, Batch 17/25, Loss: 0.12454365193843842\n",
      "Epoch 48/60, Batch 18/25, Loss: 0.1529000848531723\n",
      "Epoch 48/60, Batch 19/25, Loss: 0.1470288336277008\n",
      "Epoch 48/60, Batch 20/25, Loss: 0.14083905518054962\n",
      "Epoch 48/60, Batch 21/25, Loss: 0.17961552739143372\n",
      "Epoch 48/60, Batch 22/25, Loss: 0.12978129088878632\n",
      "Epoch 48/60, Batch 23/25, Loss: 0.110786072909832\n",
      "Epoch 48/60, Batch 24/25, Loss: 0.10992122441530228\n",
      "Epoch 48/60, Batch 25/25, Loss: 0.17449861764907837\n",
      "Saved model parameters to models/FCN_epoch48.pdparams\n",
      "Epoch 49/60, Batch 1/25, Loss: 0.14403679966926575\n",
      "Epoch 49/60, Batch 2/25, Loss: 0.10836929827928543\n",
      "Epoch 49/60, Batch 3/25, Loss: 0.12999291718006134\n",
      "Epoch 49/60, Batch 4/25, Loss: 0.10483991354703903\n",
      "Epoch 49/60, Batch 5/25, Loss: 0.18260458111763\n",
      "Epoch 49/60, Batch 6/25, Loss: 0.12804323434829712\n",
      "Epoch 49/60, Batch 7/25, Loss: 0.17944833636283875\n",
      "Epoch 49/60, Batch 8/25, Loss: 0.11382710188627243\n",
      "Epoch 49/60, Batch 9/25, Loss: 0.15775348246097565\n",
      "Epoch 49/60, Batch 10/25, Loss: 0.12539443373680115\n",
      "Epoch 49/60, Batch 11/25, Loss: 0.07992612570524216\n",
      "Epoch 49/60, Batch 12/25, Loss: 0.10056008398532867\n",
      "Epoch 49/60, Batch 13/25, Loss: 0.15935367345809937\n",
      "Epoch 49/60, Batch 14/25, Loss: 0.12443944811820984\n",
      "Epoch 49/60, Batch 15/25, Loss: 0.10362459719181061\n",
      "Epoch 49/60, Batch 16/25, Loss: 0.150909885764122\n",
      "Epoch 49/60, Batch 17/25, Loss: 0.12155738472938538\n",
      "Epoch 49/60, Batch 18/25, Loss: 0.13776648044586182\n",
      "Epoch 49/60, Batch 19/25, Loss: 0.13883018493652344\n",
      "Epoch 49/60, Batch 20/25, Loss: 0.1452922821044922\n",
      "Epoch 49/60, Batch 21/25, Loss: 0.10029736161231995\n",
      "Epoch 49/60, Batch 22/25, Loss: 0.13767585158348083\n",
      "Epoch 49/60, Batch 23/25, Loss: 0.10531141608953476\n",
      "Epoch 49/60, Batch 24/25, Loss: 0.15128721296787262\n",
      "Epoch 49/60, Batch 25/25, Loss: 0.06922256946563721\n",
      "Saved model parameters to models/FCN_epoch49.pdparams\n",
      "Epoch 50/60, Batch 1/25, Loss: 0.10228770971298218\n",
      "Epoch 50/60, Batch 2/25, Loss: 0.10659309476613998\n",
      "Epoch 50/60, Batch 3/25, Loss: 0.141193687915802\n",
      "Epoch 50/60, Batch 4/25, Loss: 0.10712741315364838\n",
      "Epoch 50/60, Batch 5/25, Loss: 0.16276881098747253\n",
      "Epoch 50/60, Batch 6/25, Loss: 0.12529748678207397\n",
      "Epoch 50/60, Batch 7/25, Loss: 0.17177997529506683\n",
      "Epoch 50/60, Batch 8/25, Loss: 0.11067560315132141\n",
      "Epoch 50/60, Batch 9/25, Loss: 0.12402654439210892\n",
      "Epoch 50/60, Batch 10/25, Loss: 0.11587713658809662\n",
      "Epoch 50/60, Batch 11/25, Loss: 0.15818971395492554\n",
      "Epoch 50/60, Batch 12/25, Loss: 0.16805343329906464\n",
      "Epoch 50/60, Batch 13/25, Loss: 0.15742506086826324\n",
      "Epoch 50/60, Batch 14/25, Loss: 0.1305605173110962\n",
      "Epoch 50/60, Batch 15/25, Loss: 0.0960625410079956\n",
      "Epoch 50/60, Batch 16/25, Loss: 0.1529238522052765\n",
      "Epoch 50/60, Batch 17/25, Loss: 0.1429264396429062\n",
      "Epoch 50/60, Batch 18/25, Loss: 0.10173137485980988\n",
      "Epoch 50/60, Batch 19/25, Loss: 0.11383361369371414\n",
      "Epoch 50/60, Batch 20/25, Loss: 0.12441068887710571\n",
      "Epoch 50/60, Batch 21/25, Loss: 0.11702169477939606\n",
      "Epoch 50/60, Batch 22/25, Loss: 0.10584952682256699\n",
      "Epoch 50/60, Batch 23/25, Loss: 0.1418607532978058\n",
      "Epoch 50/60, Batch 24/25, Loss: 0.11127771437168121\n",
      "Epoch 50/60, Batch 25/25, Loss: 0.09927762299776077\n",
      "Saved model parameters to models/FCN_epoch50.pdparams\n",
      "Epoch 51/60, Batch 1/25, Loss: 0.12838654220104218\n",
      "Epoch 51/60, Batch 2/25, Loss: 0.11995857208967209\n",
      "Epoch 51/60, Batch 3/25, Loss: 0.1692894697189331\n",
      "Epoch 51/60, Batch 4/25, Loss: 0.12822511792182922\n",
      "Epoch 51/60, Batch 5/25, Loss: 0.179796501994133\n",
      "Epoch 51/60, Batch 6/25, Loss: 0.10447905212640762\n",
      "Epoch 51/60, Batch 7/25, Loss: 0.11722853034734726\n",
      "Epoch 51/60, Batch 8/25, Loss: 0.11736053228378296\n",
      "Epoch 51/60, Batch 9/25, Loss: 0.08715467900037766\n",
      "Epoch 51/60, Batch 10/25, Loss: 0.14689874649047852\n",
      "Epoch 51/60, Batch 11/25, Loss: 0.17495079338550568\n",
      "Epoch 51/60, Batch 12/25, Loss: 0.09923121333122253\n",
      "Epoch 51/60, Batch 13/25, Loss: 0.142735555768013\n",
      "Epoch 51/60, Batch 14/25, Loss: 0.1290256679058075\n",
      "Epoch 51/60, Batch 15/25, Loss: 0.1215435191988945\n",
      "Epoch 51/60, Batch 16/25, Loss: 0.0955413430929184\n",
      "Epoch 51/60, Batch 17/25, Loss: 0.13680894672870636\n",
      "Epoch 51/60, Batch 18/25, Loss: 0.17905104160308838\n",
      "Epoch 51/60, Batch 19/25, Loss: 0.11583025753498077\n",
      "Epoch 51/60, Batch 20/25, Loss: 0.14254717528820038\n",
      "Epoch 51/60, Batch 21/25, Loss: 0.12852010130882263\n",
      "Epoch 51/60, Batch 22/25, Loss: 0.17798741161823273\n",
      "Epoch 51/60, Batch 23/25, Loss: 0.12913517653942108\n",
      "Epoch 51/60, Batch 24/25, Loss: 0.09986642748117447\n",
      "Epoch 51/60, Batch 25/25, Loss: 0.08778148889541626\n",
      "Saved model parameters to models/FCN_epoch51.pdparams\n",
      "Epoch 52/60, Batch 1/25, Loss: 0.09333375841379166\n",
      "Epoch 52/60, Batch 2/25, Loss: 0.1037435457110405\n",
      "Epoch 52/60, Batch 3/25, Loss: 0.11308825761079788\n",
      "Epoch 52/60, Batch 4/25, Loss: 0.13471625745296478\n",
      "Epoch 52/60, Batch 5/25, Loss: 0.16247393190860748\n",
      "Epoch 52/60, Batch 6/25, Loss: 0.12976910173892975\n",
      "Epoch 52/60, Batch 7/25, Loss: 0.14453738927841187\n",
      "Epoch 52/60, Batch 8/25, Loss: 0.158670574426651\n",
      "Epoch 52/60, Batch 9/25, Loss: 0.12812668085098267\n",
      "Epoch 52/60, Batch 10/25, Loss: 0.1098998486995697\n",
      "Epoch 52/60, Batch 11/25, Loss: 0.12274746596813202\n",
      "Epoch 52/60, Batch 12/25, Loss: 0.13028717041015625\n",
      "Epoch 52/60, Batch 13/25, Loss: 0.08783912658691406\n",
      "Epoch 52/60, Batch 14/25, Loss: 0.18635249137878418\n",
      "Epoch 52/60, Batch 15/25, Loss: 0.16678768396377563\n",
      "Epoch 52/60, Batch 16/25, Loss: 0.1314597725868225\n",
      "Epoch 52/60, Batch 17/25, Loss: 0.13436183333396912\n",
      "Epoch 52/60, Batch 18/25, Loss: 0.10154198110103607\n",
      "Epoch 52/60, Batch 19/25, Loss: 0.13519889116287231\n",
      "Epoch 52/60, Batch 20/25, Loss: 0.17867207527160645\n",
      "Epoch 52/60, Batch 21/25, Loss: 0.13863618671894073\n",
      "Epoch 52/60, Batch 22/25, Loss: 0.1438537836074829\n",
      "Epoch 52/60, Batch 23/25, Loss: 0.13012398779392242\n",
      "Epoch 52/60, Batch 24/25, Loss: 0.08720728754997253\n",
      "Epoch 52/60, Batch 25/25, Loss: 0.12852069735527039\n",
      "Saved model parameters to models/FCN_epoch52.pdparams\n",
      "Epoch 53/60, Batch 1/25, Loss: 0.10360608249902725\n",
      "Epoch 53/60, Batch 2/25, Loss: 0.1303362399339676\n",
      "Epoch 53/60, Batch 3/25, Loss: 0.15089796483516693\n",
      "Epoch 53/60, Batch 4/25, Loss: 0.10861113667488098\n",
      "Epoch 53/60, Batch 5/25, Loss: 0.15393614768981934\n",
      "Epoch 53/60, Batch 6/25, Loss: 0.17350180447101593\n",
      "Epoch 53/60, Batch 7/25, Loss: 0.10278291255235672\n",
      "Epoch 53/60, Batch 8/25, Loss: 0.16006432473659515\n",
      "Epoch 53/60, Batch 9/25, Loss: 0.13605530560016632\n",
      "Epoch 53/60, Batch 10/25, Loss: 0.12361466884613037\n",
      "Epoch 53/60, Batch 11/25, Loss: 0.12281518429517746\n",
      "Epoch 53/60, Batch 12/25, Loss: 0.14428047835826874\n",
      "Epoch 53/60, Batch 13/25, Loss: 0.14085565507411957\n",
      "Epoch 53/60, Batch 14/25, Loss: 0.1380346715450287\n",
      "Epoch 53/60, Batch 15/25, Loss: 0.07638707756996155\n",
      "Epoch 53/60, Batch 16/25, Loss: 0.14374835789203644\n",
      "Epoch 53/60, Batch 17/25, Loss: 0.12391475588083267\n",
      "Epoch 53/60, Batch 18/25, Loss: 0.12979717552661896\n",
      "Epoch 53/60, Batch 19/25, Loss: 0.08509647846221924\n",
      "Epoch 53/60, Batch 20/25, Loss: 0.12038585543632507\n",
      "Epoch 53/60, Batch 21/25, Loss: 0.11771522462368011\n",
      "Epoch 53/60, Batch 22/25, Loss: 0.19069916009902954\n",
      "Epoch 53/60, Batch 23/25, Loss: 0.09661656618118286\n",
      "Epoch 53/60, Batch 24/25, Loss: 0.08742020279169083\n",
      "Epoch 53/60, Batch 25/25, Loss: 0.15370327234268188\n",
      "Saved model parameters to models/FCN_epoch53.pdparams\n",
      "Epoch 54/60, Batch 1/25, Loss: 0.10829959064722061\n",
      "Epoch 54/60, Batch 2/25, Loss: 0.1327587366104126\n",
      "Epoch 54/60, Batch 3/25, Loss: 0.1193716898560524\n",
      "Epoch 54/60, Batch 4/25, Loss: 0.1323196142911911\n",
      "Epoch 54/60, Batch 5/25, Loss: 0.12857046723365784\n",
      "Epoch 54/60, Batch 6/25, Loss: 0.11653019487857819\n",
      "Epoch 54/60, Batch 7/25, Loss: 0.10409784317016602\n",
      "Epoch 54/60, Batch 8/25, Loss: 0.1238294467329979\n",
      "Epoch 54/60, Batch 9/25, Loss: 0.17497111856937408\n",
      "Epoch 54/60, Batch 10/25, Loss: 0.09582538157701492\n",
      "Epoch 54/60, Batch 11/25, Loss: 0.1718963384628296\n",
      "Epoch 54/60, Batch 12/25, Loss: 0.1187935546040535\n",
      "Epoch 54/60, Batch 13/25, Loss: 0.13978253304958344\n",
      "Epoch 54/60, Batch 14/25, Loss: 0.13601846992969513\n",
      "Epoch 54/60, Batch 15/25, Loss: 0.11872521787881851\n",
      "Epoch 54/60, Batch 16/25, Loss: 0.21559660136699677\n",
      "Epoch 54/60, Batch 17/25, Loss: 0.09767790883779526\n",
      "Epoch 54/60, Batch 18/25, Loss: 0.08046986162662506\n",
      "Epoch 54/60, Batch 19/25, Loss: 0.18883059918880463\n",
      "Epoch 54/60, Batch 20/25, Loss: 0.0994475930929184\n",
      "Epoch 54/60, Batch 21/25, Loss: 0.0894731879234314\n",
      "Epoch 54/60, Batch 22/25, Loss: 0.11316870898008347\n",
      "Epoch 54/60, Batch 23/25, Loss: 0.10369624197483063\n",
      "Epoch 54/60, Batch 24/25, Loss: 0.15146629512310028\n",
      "Epoch 54/60, Batch 25/25, Loss: 0.09238653630018234\n",
      "Saved model parameters to models/FCN_epoch54.pdparams\n",
      "Epoch 55/60, Batch 1/25, Loss: 0.10070136934518814\n",
      "Epoch 55/60, Batch 2/25, Loss: 0.1325220912694931\n",
      "Epoch 55/60, Batch 3/25, Loss: 0.14003585278987885\n",
      "Epoch 55/60, Batch 4/25, Loss: 0.12651921808719635\n",
      "Epoch 55/60, Batch 5/25, Loss: 0.14412158727645874\n",
      "Epoch 55/60, Batch 6/25, Loss: 0.11931916326284409\n",
      "Epoch 55/60, Batch 7/25, Loss: 0.12187305092811584\n",
      "Epoch 55/60, Batch 8/25, Loss: 0.1345910280942917\n",
      "Epoch 55/60, Batch 9/25, Loss: 0.08819089084863663\n",
      "Epoch 55/60, Batch 10/25, Loss: 0.13914042711257935\n",
      "Epoch 55/60, Batch 11/25, Loss: 0.16666144132614136\n",
      "Epoch 55/60, Batch 12/25, Loss: 0.10440561920404434\n",
      "Epoch 55/60, Batch 13/25, Loss: 0.0986032485961914\n",
      "Epoch 55/60, Batch 14/25, Loss: 0.11167830973863602\n",
      "Epoch 55/60, Batch 15/25, Loss: 0.12999606132507324\n",
      "Epoch 55/60, Batch 16/25, Loss: 0.17607082426548004\n",
      "Epoch 55/60, Batch 17/25, Loss: 0.14927436411380768\n",
      "Epoch 55/60, Batch 18/25, Loss: 0.09573088586330414\n",
      "Epoch 55/60, Batch 19/25, Loss: 0.1204596608877182\n",
      "Epoch 55/60, Batch 20/25, Loss: 0.12523669004440308\n",
      "Epoch 55/60, Batch 21/25, Loss: 0.1289140284061432\n",
      "Epoch 55/60, Batch 22/25, Loss: 0.12852969765663147\n",
      "Epoch 55/60, Batch 23/25, Loss: 0.11569494009017944\n",
      "Epoch 55/60, Batch 24/25, Loss: 0.12254706025123596\n",
      "Epoch 55/60, Batch 25/25, Loss: 0.13729967176914215\n",
      "Saved model parameters to models/FCN_epoch55.pdparams\n",
      "Epoch 56/60, Batch 1/25, Loss: 0.10366486012935638\n",
      "Epoch 56/60, Batch 2/25, Loss: 0.13397786021232605\n",
      "Epoch 56/60, Batch 3/25, Loss: 0.0974845364689827\n",
      "Epoch 56/60, Batch 4/25, Loss: 0.11026807874441147\n",
      "Epoch 56/60, Batch 5/25, Loss: 0.12453293055295944\n",
      "Epoch 56/60, Batch 6/25, Loss: 0.10014262795448303\n",
      "Epoch 56/60, Batch 7/25, Loss: 0.09279070794582367\n",
      "Epoch 56/60, Batch 8/25, Loss: 0.11340411752462387\n",
      "Epoch 56/60, Batch 9/25, Loss: 0.1441984325647354\n",
      "Epoch 56/60, Batch 10/25, Loss: 0.11261503398418427\n",
      "Epoch 56/60, Batch 11/25, Loss: 0.1563665270805359\n",
      "Epoch 56/60, Batch 12/25, Loss: 0.1577751338481903\n",
      "Epoch 56/60, Batch 13/25, Loss: 0.1421959102153778\n",
      "Epoch 56/60, Batch 14/25, Loss: 0.13046348094940186\n",
      "Epoch 56/60, Batch 15/25, Loss: 0.12453532963991165\n",
      "Epoch 56/60, Batch 16/25, Loss: 0.11275264620780945\n",
      "Epoch 56/60, Batch 17/25, Loss: 0.08654226362705231\n",
      "Epoch 56/60, Batch 18/25, Loss: 0.1369398683309555\n",
      "Epoch 56/60, Batch 19/25, Loss: 0.09092660993337631\n",
      "Epoch 56/60, Batch 20/25, Loss: 0.15922115743160248\n",
      "Epoch 56/60, Batch 21/25, Loss: 0.11020504683256149\n",
      "Epoch 56/60, Batch 22/25, Loss: 0.1210063099861145\n",
      "Epoch 56/60, Batch 23/25, Loss: 0.12643744051456451\n",
      "Epoch 56/60, Batch 24/25, Loss: 0.15138483047485352\n",
      "Epoch 56/60, Batch 25/25, Loss: 0.1642688363790512\n",
      "Saved model parameters to models/FCN_epoch56.pdparams\n",
      "Epoch 57/60, Batch 1/25, Loss: 0.11687824130058289\n",
      "Epoch 57/60, Batch 2/25, Loss: 0.13401442766189575\n",
      "Epoch 57/60, Batch 3/25, Loss: 0.15457874536514282\n",
      "Epoch 57/60, Batch 4/25, Loss: 0.13503368198871613\n",
      "Epoch 57/60, Batch 5/25, Loss: 0.14016669988632202\n",
      "Epoch 57/60, Batch 6/25, Loss: 0.08719497919082642\n",
      "Epoch 57/60, Batch 7/25, Loss: 0.05462760850787163\n",
      "Epoch 57/60, Batch 8/25, Loss: 0.17248547077178955\n",
      "Epoch 57/60, Batch 9/25, Loss: 0.14302171766757965\n",
      "Epoch 57/60, Batch 10/25, Loss: 0.10497795045375824\n",
      "Epoch 57/60, Batch 11/25, Loss: 0.09640833735466003\n",
      "Epoch 57/60, Batch 12/25, Loss: 0.12636061012744904\n",
      "Epoch 57/60, Batch 13/25, Loss: 0.09064792096614838\n",
      "Epoch 57/60, Batch 14/25, Loss: 0.1294502168893814\n",
      "Epoch 57/60, Batch 15/25, Loss: 0.137039452791214\n",
      "Epoch 57/60, Batch 16/25, Loss: 0.12270427495241165\n",
      "Epoch 57/60, Batch 17/25, Loss: 0.12292412668466568\n",
      "Epoch 57/60, Batch 18/25, Loss: 0.11004604399204254\n",
      "Epoch 57/60, Batch 19/25, Loss: 0.110666923224926\n",
      "Epoch 57/60, Batch 20/25, Loss: 0.09124652296304703\n",
      "Epoch 57/60, Batch 21/25, Loss: 0.12328529357910156\n",
      "Epoch 57/60, Batch 22/25, Loss: 0.18593177199363708\n",
      "Epoch 57/60, Batch 23/25, Loss: 0.16038662195205688\n",
      "Epoch 57/60, Batch 24/25, Loss: 0.12691707909107208\n",
      "Epoch 57/60, Batch 25/25, Loss: 0.143122136592865\n",
      "Saved model parameters to models/FCN_epoch57.pdparams\n",
      "Epoch 58/60, Batch 1/25, Loss: 0.11781883239746094\n",
      "Epoch 58/60, Batch 2/25, Loss: 0.16238634288311005\n",
      "Epoch 58/60, Batch 3/25, Loss: 0.08656109124422073\n",
      "Epoch 58/60, Batch 4/25, Loss: 0.09321671724319458\n",
      "Epoch 58/60, Batch 5/25, Loss: 0.1102832481265068\n",
      "Epoch 58/60, Batch 6/25, Loss: 0.11987200379371643\n",
      "Epoch 58/60, Batch 7/25, Loss: 0.15561126172542572\n",
      "Epoch 58/60, Batch 8/25, Loss: 0.08105830103158951\n",
      "Epoch 58/60, Batch 9/25, Loss: 0.12369973957538605\n",
      "Epoch 58/60, Batch 10/25, Loss: 0.14375939965248108\n",
      "Epoch 58/60, Batch 11/25, Loss: 0.11227250844240189\n",
      "Epoch 58/60, Batch 12/25, Loss: 0.15592867136001587\n",
      "Epoch 58/60, Batch 13/25, Loss: 0.21805737912654877\n",
      "Epoch 58/60, Batch 14/25, Loss: 0.08723778277635574\n",
      "Epoch 58/60, Batch 15/25, Loss: 0.11254306137561798\n",
      "Epoch 58/60, Batch 16/25, Loss: 0.1378510743379593\n",
      "Epoch 58/60, Batch 17/25, Loss: 0.12574663758277893\n",
      "Epoch 58/60, Batch 18/25, Loss: 0.11724667996168137\n",
      "Epoch 58/60, Batch 19/25, Loss: 0.08480969071388245\n",
      "Epoch 58/60, Batch 20/25, Loss: 0.14175060391426086\n",
      "Epoch 58/60, Batch 21/25, Loss: 0.10745102167129517\n",
      "Epoch 58/60, Batch 22/25, Loss: 0.12130008637905121\n",
      "Epoch 58/60, Batch 23/25, Loss: 0.11432231962680817\n",
      "Epoch 58/60, Batch 24/25, Loss: 0.11379297077655792\n",
      "Epoch 58/60, Batch 25/25, Loss: 0.11747988313436508\n",
      "Saved model parameters to models/FCN_epoch58.pdparams\n",
      "Epoch 59/60, Batch 1/25, Loss: 0.1285872608423233\n",
      "Epoch 59/60, Batch 2/25, Loss: 0.11222979426383972\n",
      "Epoch 59/60, Batch 3/25, Loss: 0.102466881275177\n",
      "Epoch 59/60, Batch 4/25, Loss: 0.09183000028133392\n",
      "Epoch 59/60, Batch 5/25, Loss: 0.12852004170417786\n",
      "Epoch 59/60, Batch 6/25, Loss: 0.11121834814548492\n",
      "Epoch 59/60, Batch 7/25, Loss: 0.19113728404045105\n",
      "Epoch 59/60, Batch 8/25, Loss: 0.12361714243888855\n",
      "Epoch 59/60, Batch 9/25, Loss: 0.11927763372659683\n",
      "Epoch 59/60, Batch 10/25, Loss: 0.10676603019237518\n",
      "Epoch 59/60, Batch 11/25, Loss: 0.11867900937795639\n",
      "Epoch 59/60, Batch 12/25, Loss: 0.10090550035238266\n",
      "Epoch 59/60, Batch 13/25, Loss: 0.09971696138381958\n",
      "Epoch 59/60, Batch 14/25, Loss: 0.20227985084056854\n",
      "Epoch 59/60, Batch 15/25, Loss: 0.14711950719356537\n",
      "Epoch 59/60, Batch 16/25, Loss: 0.0946076288819313\n",
      "Epoch 59/60, Batch 17/25, Loss: 0.09853662550449371\n",
      "Epoch 59/60, Batch 18/25, Loss: 0.10649961978197098\n",
      "Epoch 59/60, Batch 19/25, Loss: 0.12904201447963715\n",
      "Epoch 59/60, Batch 20/25, Loss: 0.1276511698961258\n",
      "Epoch 59/60, Batch 21/25, Loss: 0.18337878584861755\n",
      "Epoch 59/60, Batch 22/25, Loss: 0.09957937151193619\n",
      "Epoch 59/60, Batch 23/25, Loss: 0.09635178744792938\n",
      "Epoch 59/60, Batch 24/25, Loss: 0.11748823523521423\n",
      "Epoch 59/60, Batch 25/25, Loss: 0.132339745759964\n",
      "Saved model parameters to models/FCN_epoch59.pdparams\n",
      "Epoch 60/60, Batch 1/25, Loss: 0.09856951236724854\n",
      "Epoch 60/60, Batch 2/25, Loss: 0.1117691844701767\n",
      "Epoch 60/60, Batch 3/25, Loss: 0.0962064117193222\n",
      "Epoch 60/60, Batch 4/25, Loss: 0.12477725744247437\n",
      "Epoch 60/60, Batch 5/25, Loss: 0.22110430896282196\n",
      "Epoch 60/60, Batch 6/25, Loss: 0.08529200404882431\n",
      "Epoch 60/60, Batch 7/25, Loss: 0.13071754574775696\n",
      "Epoch 60/60, Batch 8/25, Loss: 0.12583333253860474\n",
      "Epoch 60/60, Batch 9/25, Loss: 0.10390958935022354\n",
      "Epoch 60/60, Batch 10/25, Loss: 0.1131550744175911\n",
      "Epoch 60/60, Batch 11/25, Loss: 0.10317536443471909\n",
      "Epoch 60/60, Batch 12/25, Loss: 0.10671378672122955\n",
      "Epoch 60/60, Batch 13/25, Loss: 0.1371661126613617\n",
      "Epoch 60/60, Batch 14/25, Loss: 0.14120271801948547\n",
      "Epoch 60/60, Batch 15/25, Loss: 0.11141372472047806\n",
      "Epoch 60/60, Batch 16/25, Loss: 0.13951802253723145\n",
      "Epoch 60/60, Batch 17/25, Loss: 0.16211004555225372\n",
      "Epoch 60/60, Batch 18/25, Loss: 0.12386491894721985\n",
      "Epoch 60/60, Batch 19/25, Loss: 0.08799131959676743\n",
      "Epoch 60/60, Batch 20/25, Loss: 0.13854961097240448\n",
      "Epoch 60/60, Batch 21/25, Loss: 0.1438809037208557\n"
     ]
    }
   ],
   "source": [
    "# 1. 初始化模型\n",
    "model = FCN(num_classes=1)\n",
    "\n",
    "# 2. 加载模型参数\n",
    "start_epoch = 19  # 假设你想从第3个epoch开始训练\n",
    "model_path = os.path.join(\"models\", f\"FCN_epoch{start_epoch}.pdparams\")\n",
    "model_state_dict = paddle.load(model_path)\n",
    "model.set_state_dict(model_state_dict)\n",
    "print(f\"Loaded model parameters from {model_path}\")\n",
    "\n",
    "# 3. 设置损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(parameters=model.parameters(), learning_rate=0.001)\n",
    "\n",
    "# 4. 继续训练\n",
    "epochs = 60\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.numpy()[0]}\")\n",
    "        \n",
    "        # 记录loss到VisualDL\n",
    "        global_step = epoch * len(train_loader) + batch_idx\n",
    "        writer.add_scalar(tag=\"train/loss\", step=global_step, value=loss.numpy()[0])\n",
    "\n",
    "    # 每个epoch结束后保存模型\n",
    "    model_path = os.path.join(\"models\", f\"FCN_epoch{epoch+1}.pdparams\")\n",
    "    paddle.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model parameters to {model_path}\")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb58aa-f5d4-4e45-a440-0be6559e8b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3dbdd1-0cb5-480e-8aa1-9e60da5e9a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试单张\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 初始化模型\n",
    "model = FCN(num_classes=1)\n",
    "\n",
    "def predict_single_image(model, image_path, transform_size=(512, 512)):\n",
    "    # 加载和预处理图像\n",
    "    image = Image.open(image_path).convert('RGB').resize(transform_size)\n",
    "    image_tensor = paddle.to_tensor(np.array(image).astype('float32').transpose((2, 0, 1)) / 255.0)\n",
    "    image_tensor = paddle.unsqueeze(image_tensor, 0)  # 添加batch维度\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    model.eval()\n",
    "    with paddle.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        predicted_mask = (output > 0.5).astype('float32')\n",
    "\n",
    "    # 将预测的掩码转换回图像格式\n",
    "    mask_img = Image.fromarray((predicted_mask[0][0].numpy() * 255).astype(np.uint8)).resize((2000, 2000))\n",
    "    \n",
    "    return mask_img\n",
    "\n",
    "# 加载模型参数\n",
    "model_path = \"FCN_models/FCN_epoch50.pdparams\"\n",
    "model_state_dict = paddle.load(model_path)\n",
    "model.set_state_dict(model_state_dict)\n",
    "\n",
    "# 预测单张图像\n",
    "image_path = \"V0017.jpg\"\n",
    "predicted_mask_img = predict_single_image(model, image_path)\n",
    "\n",
    "# 展示预测的掩码\n",
    "plt.imshow(predicted_mask_img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# 保存预测的掩码\n",
    "predicted_mask_img.save(\"V0017.bmp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647216cb-0028-46de-9ff9-1b42a4066933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
